{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb15d82",
   "metadata": {},
   "source": [
    "Given a character or sequence of characters, we want to predict the next character at each time step.\n",
    "Model is trained to follow a language similar to the works of Shakespeare. The tinyshakespear dataset is used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "88e449b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127be92",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b00a5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(URL):\n",
    "    with io.open(URL, 'r', encoding='utf8') as f:\n",
    "        text = f.read()\n",
    "    # Character's collection\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0f45d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(read_text(\"shakespeare_train.txt\")[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c16ad",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b189cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#character to index\n",
    "def character_to_index(sub_txt, dict_int):\n",
    "    encoded_text = np.array([dict_int[c] for c in sub_txt], dtype=np.int32)  # encode data\n",
    "    return encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c77066ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index to character\n",
    "def index_to_char(index_list, dict_char):\n",
    "    text = []\n",
    "    for i in index_list:\n",
    "        text.append(dict_char[i])\n",
    "    return (repr( ''.join(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38290a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_int = {u:i for i, u in enumerate(read_text(\"shakespeare_train.txt\")[:100])}\n",
    "dict_char = dict(enumerate(read_text(\"shakespeare_train.txt\")[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "409d1378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character to Index: \n",
      "\n",
      "  'F' :  82\n",
      "  'i' :  91\n",
      "  'r' :  84\n",
      "  's' :  85\n",
      "  't' :  90\n",
      "  ' ' :  87\n",
      "  'C' :  88\n",
      "  'z' :  92\n",
      "  'e' :  93\n",
      "  'n' :  94\n",
      "  ':' :  95\n",
      "  '\\n':  96\n",
      "  'B' :  15\n",
      "  'f' :  37\n",
      "  'o' :  98\n",
      "  'w' :  22\n",
      "  'p' :  75\n",
      "  'c' :  28\n",
      "  'd' :  31\n",
      "  'a' :  77\n",
      "  'y' :  35\n",
      "  'u' :  99\n",
      "  'h' :  46\n",
      "  ',' :  72\n",
      "  'm' :  51\n",
      "  'k' :  78\n",
      "  '.' :  79\n",
      "  'A' :  62\n",
      "  'l' :  64\n",
      "  'S' :  67\n",
      "  'Y' :  97\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(\"Character to Index: \\n\")\n",
    "for char,_ in zip(dict_int, range(65)):\n",
    "    print('  {:4s}: {:3d}'.format(repr(char), dict_int[char]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f20aac",
   "metadata": {},
   "source": [
    "# Create training examples / targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45eaa6e",
   "metadata": {},
   "source": [
    "Target value: for each sequence of characters, we return that sequence, shifted one position to the right, along with the new character that is predicted to follow the sequence.\n",
    "\n",
    "To create training examples of (input, target) pairs, we take the given sequence. The input is sequence with last word removed. Target is sequence with first word removed. Example: sequence: abc d ef input: abc d e target: bc d ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec462e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6c1f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples / targets\n",
    "def handle_data(data, seq_len):\n",
    "    \"\"\"\n",
    "    this function to create data from row data\n",
    "\n",
    "    :param data: row data with int type\n",
    "    :param seq_len: max len of input and output sequence\n",
    "    :return: data for training\n",
    "    \"\"\"\n",
    "    #data4epoch = len(data) // (seq_len+1)\n",
    "    # Create training examples / targets\n",
    "    char_dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    sequences = char_dataset.batch(seq_len + 1, drop_remainder=True)\n",
    "    dataset = sequences.map(split_input_target)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38dccf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = read_text('shakespeare_train.txt')\n",
    "val_set = read_text('shakespeare_valid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abad86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#union vocab\n",
    "vocab_train = set(training_set)\n",
    "vocab_val = set(val_set)\n",
    "vocab = vocab_train.union(vocab_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4bec5592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set character that were found in text to the dict\n",
    "dict_int = {u:i for i, u in enumerate(vocab)}\n",
    "dict_char =dict(enumerate(vocab))\n",
    "\n",
    "train_x = character_to_index(training_set, dict_int)\n",
    "val_x = character_to_index(val_set, dict_int)\n",
    "\n",
    "seq_len = 50 # max number of characters that can be fed as a single input\n",
    "\n",
    "#Create sequences from the individual characters. Our required size will be seq_len + 1 (character RNN)\n",
    "train_seq = len(train_x) // (seq_len + 1)\n",
    "val_seq = len(val_x) // (seq_len + 1)\n",
    "\n",
    "data_train = handle_data(train_x, seq_len) # include input and target\n",
    "data_val = handle_data(val_x, seq_len)  # include input and target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4ce49",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "85f0941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "iterator_train = train_seq // BATCH_SIZE\n",
    "iterator_val = val_seq // BATCH_SIZE\n",
    "\n",
    "# Buffer used to shuffle the dataset\n",
    "BUFFER_SIZE = train_seq + val_seq\n",
    "data_train = data_train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "data_val = data_val.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "112a47e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(cellType, vocab_size, embedding_dim, rnn_units, BATCH_SIZE):\n",
    "    if (cellType == \"LSTM\"):\n",
    "        rnn = tf.keras.layers.LSTM\n",
    "    elif (cellType == \"GRU\"):\n",
    "        rnn = tf.keras.layers.GRU\n",
    "    else:\n",
    "        rnn = tf.keras.layers.SimpleRNN\n",
    "\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[BATCH_SIZE, None]),\n",
    "                                 rnn(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                                 tf.keras.layers.Dense(vocab_size)])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03e73544",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "422998ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (64, None, 256)           17152     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, None, 67)            68675     \n",
      "=================================================================\n",
      "Total params: 5,332,803\n",
      "Trainable params: 5,332,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cellType  = \"LSTM\" \n",
    "model = built_model(cellType, vocab_size, embedding_dim, rnn_units, BATCH_SIZE)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f3a1f9",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "334208ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "586a2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "82450e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dir_checkpoints= 'training_checkpoints_LSTM'\n",
    "checkpoint_prefix = os.path.join(lstm_dir_checkpoints, \"chkpt_{epoch}\")\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f0a491e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1333/1333 [==============================] - 1381s 1s/step - loss: 1.9446\n",
      "Epoch 2/100\n",
      "1333/1333 [==============================] - 1390s 1s/step - loss: 1.4961\n",
      "Epoch 3/100\n",
      "1333/1333 [==============================] - 1297s 970ms/step - loss: 1.4161\n",
      "Epoch 4/100\n",
      "1333/1333 [==============================] - 1314s 984ms/step - loss: 1.3758\n",
      "Epoch 5/100\n",
      "1333/1333 [==============================] - 1303s 975ms/step - loss: 1.3478\n",
      "Epoch 6/100\n",
      "1333/1333 [==============================] - 1262s 944ms/step - loss: 1.3254\n",
      "Epoch 7/100\n",
      " 567/1333 [===========>..................] - ETA: 12:16 - loss: 1.3049"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2504/806094054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "history = model.fit(data_train, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63eb22e",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Internship",
   "language": "python",
   "name": "internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
