{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMucfLUS1yhH"
   },
   "source": [
    "## What is this?\n",
    "\n",
    "This Jupyter Notebook contains Python code for building a LSTM Recurrent Neural Network that gives 87-88% accuracy on the IMDB Movie Review Sentiment Analysis Dataset. \n",
    "\n",
    "More information is given on [this blogpost](https://www.bouvet.no/bouvet-deler/explaining-recurrent-neural-networks).\n",
    "\n",
    "This code is supplied without license, warranty or support. Feel free to do with it what you will."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFUKGe4x3ala"
   },
   "source": [
    "## Built for Google Collaboratory\n",
    "\n",
    "Train your network more quickly in Google Collaboratory. From the **Runtime** menu select **Change Runtime** Type and choose \"GPU\"!\n",
    "\n",
    "Don't forget to select **Runtime** -> **Restart runtime** to put your changes into effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WP1VrbVp3sVu"
   },
   "source": [
    "## Setting up\n",
    "\n",
    "When running this for the first time you may get a warning telling you to restart the Runtime. You can ignore this, but feel free to select \"Runtime->Restart Runtime\" from the overhead menu if you encounter problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e3txwbh3q76",
    "outputId": "c4880c87-61b6-4c4a-ccc6-4a44faae275c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "D:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "D:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# keras.datasets.imdb is broken in TensorFlow 1.13 and 1.14 due to numpy 1.16.3\n",
    "# All the imports!\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from numpy import array\n",
    "\n",
    "# Supress deprecation warnings\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "# Fetch \"IMDB Movie Review\" data, constraining our reviews to \n",
    "# the 10000 most commonly used words\n",
    "vocab_size = 10000\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# Map for readable classnames\n",
    "class_names = [\"Negative\", \"Positive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgpxWpNb9OWB"
   },
   "source": [
    "## Read and Analyzing the X_train & Y_train with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "UROuuEn175XJ",
    "outputId": "5744cf32-00dd-47e4-ebf1-7a51107d1f80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>[1, 14, 9, 6, 2758, 20, 21, 1517, 7, 2078, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>[1, 4679, 2784, 299, 6, 1042, 37, 80, 81, 233,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>[1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>[1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>[1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0      [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, ...\n",
       "1      [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463,...\n",
       "2      [1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5...\n",
       "3      [1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153,...\n",
       "4      [1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 1...\n",
       "...                                                  ...\n",
       "24995  [1, 14, 9, 6, 2758, 20, 21, 1517, 7, 2078, 5, ...\n",
       "24996  [1, 4679, 2784, 299, 6, 1042, 37, 80, 81, 233,...\n",
       "24997  [1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2,...\n",
       "24998  [1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8,...\n",
       "24999  [1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8...\n",
       "\n",
       "[25000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x_train\n",
    "df = pd.DataFrame(x_train)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "MaOZW4XX9WbG",
    "outputId": "d830f2f5-bcad-4200-f407-d83d872aba7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "...   ..\n",
       "24995  1\n",
       "24996  0\n",
       "24997  0\n",
       "24998  1\n",
       "24999  0\n",
       "\n",
       "[25000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_train\n",
    "df2 = pd.DataFrame(y_train)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdyHL8FF0JJy"
   },
   "source": [
    "## Create map for converting IMDB dataset to readable reviews\n",
    "\n",
    "Reviews in the IMDB dataset have been encoded as a sequence of integers. Luckily the dataset also \n",
    "contains an index for converting the reviews back into human readable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E05AweFu0Imt",
    "outputId": "cf26e4f2-8fba-4b56-ada7-5a14ca1b9ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Get the word index from the dataset\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "# Ensure that \"special\" words are mapped into human readable terms \n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNKNOWN>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# Perform reverse word lookup and make it callable\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2jJLpj31s_D",
    "outputId": "c35fb864-eaf1-46e1-e95f-ee9d0496a813"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fawn': 34704,\n",
       " 'tsukino': 52009,\n",
       " 'nunnery': 52010,\n",
       " 'sonja': 16819,\n",
       " 'vani': 63954,\n",
       " 'woods': 1411,\n",
       " 'spiders': 16118,\n",
       " 'hanging': 2348,\n",
       " 'woody': 2292,\n",
       " 'trawling': 52011,\n",
       " \"hold's\": 52012,\n",
       " 'comically': 11310,\n",
       " 'localized': 40833,\n",
       " 'disobeying': 30571,\n",
       " \"'royale\": 52013,\n",
       " \"harpo's\": 40834,\n",
       " 'canet': 52014,\n",
       " 'aileen': 19316,\n",
       " 'acurately': 52015,\n",
       " \"diplomat's\": 52016,\n",
       " 'rickman': 25245,\n",
       " 'arranged': 6749,\n",
       " 'rumbustious': 52017,\n",
       " 'familiarness': 52018,\n",
       " \"spider'\": 52019,\n",
       " 'hahahah': 68807,\n",
       " \"wood'\": 52020,\n",
       " 'transvestism': 40836,\n",
       " \"hangin'\": 34705,\n",
       " 'bringing': 2341,\n",
       " 'seamier': 40837,\n",
       " 'wooded': 34706,\n",
       " 'bravora': 52021,\n",
       " 'grueling': 16820,\n",
       " 'wooden': 1639,\n",
       " 'wednesday': 16821,\n",
       " \"'prix\": 52022,\n",
       " 'altagracia': 34707,\n",
       " 'circuitry': 52023,\n",
       " 'crotch': 11588,\n",
       " 'busybody': 57769,\n",
       " \"tart'n'tangy\": 52024,\n",
       " 'burgade': 14132,\n",
       " 'thrace': 52026,\n",
       " \"tom's\": 11041,\n",
       " 'snuggles': 52028,\n",
       " 'francesco': 29117,\n",
       " 'complainers': 52030,\n",
       " 'templarios': 52128,\n",
       " '272': 40838,\n",
       " '273': 52031,\n",
       " 'zaniacs': 52133,\n",
       " '275': 34709,\n",
       " 'consenting': 27634,\n",
       " 'snuggled': 40839,\n",
       " 'inanimate': 15495,\n",
       " 'uality': 52033,\n",
       " 'bronte': 11929,\n",
       " 'errors': 4013,\n",
       " 'dialogs': 3233,\n",
       " \"yomada's\": 52034,\n",
       " \"madman's\": 34710,\n",
       " 'dialoge': 30588,\n",
       " 'usenet': 52036,\n",
       " 'videodrome': 40840,\n",
       " \"kid'\": 26341,\n",
       " 'pawed': 52037,\n",
       " \"'girlfriend'\": 30572,\n",
       " \"'pleasure\": 52038,\n",
       " \"'reloaded'\": 52039,\n",
       " \"kazakos'\": 40842,\n",
       " 'rocque': 52040,\n",
       " 'mailings': 52041,\n",
       " 'brainwashed': 11930,\n",
       " 'mcanally': 16822,\n",
       " \"tom''\": 52042,\n",
       " 'kurupt': 25246,\n",
       " 'affiliated': 21908,\n",
       " 'babaganoosh': 52043,\n",
       " \"noe's\": 40843,\n",
       " 'quart': 40844,\n",
       " 'kids': 362,\n",
       " 'uplifting': 5037,\n",
       " 'controversy': 7096,\n",
       " 'kida': 21909,\n",
       " 'kidd': 23382,\n",
       " \"error'\": 52044,\n",
       " 'neurologist': 52045,\n",
       " 'spotty': 18513,\n",
       " 'cobblers': 30573,\n",
       " 'projection': 9881,\n",
       " 'fastforwarding': 40845,\n",
       " 'sters': 52046,\n",
       " \"eggar's\": 52047,\n",
       " 'etherything': 52048,\n",
       " 'gateshead': 40846,\n",
       " 'airball': 34711,\n",
       " 'unsinkable': 25247,\n",
       " 'stern': 7183,\n",
       " \"cervi's\": 52049,\n",
       " 'dnd': 40847,\n",
       " 'dna': 11589,\n",
       " 'insecurity': 20601,\n",
       " \"'reboot'\": 52050,\n",
       " 'trelkovsky': 11040,\n",
       " 'jaekel': 52051,\n",
       " 'sidebars': 52052,\n",
       " \"sforza's\": 52053,\n",
       " 'distortions': 17636,\n",
       " 'mutinies': 52054,\n",
       " 'sermons': 30605,\n",
       " '7ft': 40849,\n",
       " 'boobage': 52055,\n",
       " \"o'bannon's\": 52056,\n",
       " 'populations': 23383,\n",
       " 'chulak': 52057,\n",
       " 'mesmerize': 27636,\n",
       " 'quinnell': 52058,\n",
       " 'yahoo': 10310,\n",
       " 'meteorologist': 52060,\n",
       " 'beswick': 42580,\n",
       " 'boorman': 15496,\n",
       " 'voicework': 40850,\n",
       " \"ster'\": 52061,\n",
       " 'blustering': 22925,\n",
       " 'hj': 52062,\n",
       " 'intake': 27637,\n",
       " 'morally': 5624,\n",
       " 'jumbling': 40852,\n",
       " 'bowersock': 52063,\n",
       " \"'porky's'\": 52064,\n",
       " 'gershon': 16824,\n",
       " 'ludicrosity': 40853,\n",
       " 'coprophilia': 52065,\n",
       " 'expressively': 40854,\n",
       " \"india's\": 19503,\n",
       " \"post's\": 34713,\n",
       " 'wana': 52066,\n",
       " 'wang': 5286,\n",
       " 'wand': 30574,\n",
       " 'wane': 25248,\n",
       " 'edgeways': 52324,\n",
       " 'titanium': 34714,\n",
       " 'pinta': 40855,\n",
       " 'want': 181,\n",
       " 'pinto': 30575,\n",
       " 'whoopdedoodles': 52068,\n",
       " 'tchaikovsky': 21911,\n",
       " 'travel': 2106,\n",
       " \"'victory'\": 52069,\n",
       " 'copious': 11931,\n",
       " 'gouge': 22436,\n",
       " \"chapters'\": 52070,\n",
       " 'barbra': 6705,\n",
       " 'uselessness': 30576,\n",
       " \"wan'\": 52071,\n",
       " 'assimilated': 27638,\n",
       " 'petiot': 16119,\n",
       " 'most\\x85and': 52072,\n",
       " 'dinosaurs': 3933,\n",
       " 'wrong': 355,\n",
       " 'seda': 52073,\n",
       " 'stollen': 52074,\n",
       " 'sentencing': 34715,\n",
       " 'ouroboros': 40856,\n",
       " 'assimilates': 40857,\n",
       " 'colorfully': 40858,\n",
       " 'glenne': 27639,\n",
       " 'dongen': 52075,\n",
       " 'subplots': 4763,\n",
       " 'kiloton': 52076,\n",
       " 'chandon': 23384,\n",
       " \"effect'\": 34716,\n",
       " 'snugly': 27640,\n",
       " 'kuei': 40859,\n",
       " 'welcomed': 9095,\n",
       " 'dishonor': 30074,\n",
       " 'concurrence': 52078,\n",
       " 'stoicism': 23385,\n",
       " \"guys'\": 14899,\n",
       " \"beroemd'\": 52080,\n",
       " 'butcher': 6706,\n",
       " \"melfi's\": 40860,\n",
       " 'aargh': 30626,\n",
       " 'playhouse': 20602,\n",
       " 'wickedly': 11311,\n",
       " 'fit': 1183,\n",
       " 'labratory': 52081,\n",
       " 'lifeline': 40862,\n",
       " 'screaming': 1930,\n",
       " 'fix': 4290,\n",
       " 'cineliterate': 52082,\n",
       " 'fic': 52083,\n",
       " 'fia': 52084,\n",
       " 'fig': 34717,\n",
       " 'fmvs': 52085,\n",
       " 'fie': 52086,\n",
       " 'reentered': 52087,\n",
       " 'fin': 30577,\n",
       " 'doctresses': 52088,\n",
       " 'fil': 52089,\n",
       " 'zucker': 12609,\n",
       " 'ached': 31934,\n",
       " 'counsil': 52091,\n",
       " 'paterfamilias': 52092,\n",
       " 'songwriter': 13888,\n",
       " 'shivam': 34718,\n",
       " 'hurting': 9657,\n",
       " 'effects': 302,\n",
       " 'slauther': 52093,\n",
       " \"'flame'\": 52094,\n",
       " 'sommerset': 52095,\n",
       " 'interwhined': 52096,\n",
       " 'whacking': 27641,\n",
       " 'bartok': 52097,\n",
       " 'barton': 8778,\n",
       " 'frewer': 21912,\n",
       " \"fi'\": 52098,\n",
       " 'ingrid': 6195,\n",
       " 'stribor': 30578,\n",
       " 'approporiately': 52099,\n",
       " 'wobblyhand': 52100,\n",
       " 'tantalisingly': 52101,\n",
       " 'ankylosaurus': 52102,\n",
       " 'parasites': 17637,\n",
       " 'childen': 52103,\n",
       " \"jenkins'\": 52104,\n",
       " 'metafiction': 52105,\n",
       " 'golem': 17638,\n",
       " 'indiscretion': 40863,\n",
       " \"reeves'\": 23386,\n",
       " \"inamorata's\": 57784,\n",
       " 'brittannica': 52107,\n",
       " 'adapt': 7919,\n",
       " \"russo's\": 30579,\n",
       " 'guitarists': 48249,\n",
       " 'abbott': 10556,\n",
       " 'abbots': 40864,\n",
       " 'lanisha': 17652,\n",
       " 'magickal': 40866,\n",
       " 'mattter': 52108,\n",
       " \"'willy\": 52109,\n",
       " 'pumpkins': 34719,\n",
       " 'stuntpeople': 52110,\n",
       " 'estimate': 30580,\n",
       " 'ugghhh': 40867,\n",
       " 'gameplay': 11312,\n",
       " \"wern't\": 52111,\n",
       " \"n'sync\": 40868,\n",
       " 'sickeningly': 16120,\n",
       " 'chiara': 40869,\n",
       " 'disturbed': 4014,\n",
       " 'portmanteau': 40870,\n",
       " 'ineffectively': 52112,\n",
       " \"duchonvey's\": 82146,\n",
       " \"nasty'\": 37522,\n",
       " 'purpose': 1288,\n",
       " 'lazers': 52115,\n",
       " 'lightened': 28108,\n",
       " 'kaliganj': 52116,\n",
       " 'popularism': 52117,\n",
       " \"damme's\": 18514,\n",
       " 'stylistics': 30581,\n",
       " 'mindgaming': 52118,\n",
       " 'spoilerish': 46452,\n",
       " \"'corny'\": 52120,\n",
       " 'boerner': 34721,\n",
       " 'olds': 6795,\n",
       " 'bakelite': 52121,\n",
       " 'renovated': 27642,\n",
       " 'forrester': 27643,\n",
       " \"lumiere's\": 52122,\n",
       " 'gaskets': 52027,\n",
       " 'needed': 887,\n",
       " 'smight': 34722,\n",
       " 'master': 1300,\n",
       " \"edie's\": 25908,\n",
       " 'seeber': 40871,\n",
       " 'hiya': 52123,\n",
       " 'fuzziness': 52124,\n",
       " 'genesis': 14900,\n",
       " 'rewards': 12610,\n",
       " 'enthrall': 30582,\n",
       " \"'about\": 40872,\n",
       " \"recollection's\": 52125,\n",
       " 'mutilated': 11042,\n",
       " 'fatherlands': 52126,\n",
       " \"fischer's\": 52127,\n",
       " 'positively': 5402,\n",
       " '270': 34708,\n",
       " 'ahmed': 34723,\n",
       " 'zatoichi': 9839,\n",
       " 'bannister': 13889,\n",
       " 'anniversaries': 52130,\n",
       " \"helm's\": 30583,\n",
       " \"'work'\": 52131,\n",
       " 'exclaimed': 34724,\n",
       " \"'unfunny'\": 52132,\n",
       " '274': 52032,\n",
       " 'feeling': 547,\n",
       " \"wanda's\": 52134,\n",
       " 'dolan': 33269,\n",
       " '278': 52136,\n",
       " 'peacoat': 52137,\n",
       " 'brawny': 40873,\n",
       " 'mishra': 40874,\n",
       " 'worlders': 40875,\n",
       " 'protags': 52138,\n",
       " 'skullcap': 52139,\n",
       " 'dastagir': 57599,\n",
       " 'affairs': 5625,\n",
       " 'wholesome': 7802,\n",
       " 'hymen': 52140,\n",
       " 'paramedics': 25249,\n",
       " 'unpersons': 52141,\n",
       " 'heavyarms': 52142,\n",
       " 'affaire': 52143,\n",
       " 'coulisses': 52144,\n",
       " 'hymer': 40876,\n",
       " 'kremlin': 52145,\n",
       " 'shipments': 30584,\n",
       " 'pixilated': 52146,\n",
       " \"'00s\": 30585,\n",
       " 'diminishing': 18515,\n",
       " 'cinematic': 1360,\n",
       " 'resonates': 14901,\n",
       " 'simplify': 40877,\n",
       " \"nature'\": 40878,\n",
       " 'temptresses': 40879,\n",
       " 'reverence': 16825,\n",
       " 'resonated': 19505,\n",
       " 'dailey': 34725,\n",
       " '2\\x85': 52147,\n",
       " 'treize': 27644,\n",
       " 'majo': 52148,\n",
       " 'kiya': 21913,\n",
       " 'woolnough': 52149,\n",
       " 'thanatos': 39800,\n",
       " 'sandoval': 35734,\n",
       " 'dorama': 40882,\n",
       " \"o'shaughnessy\": 52150,\n",
       " 'tech': 4991,\n",
       " 'fugitives': 32021,\n",
       " 'teck': 30586,\n",
       " \"'e'\": 76128,\n",
       " 'doesn’t': 40884,\n",
       " 'purged': 52152,\n",
       " 'saying': 660,\n",
       " \"martians'\": 41098,\n",
       " 'norliss': 23421,\n",
       " 'dickey': 27645,\n",
       " 'dicker': 52155,\n",
       " \"'sependipity\": 52156,\n",
       " 'padded': 8425,\n",
       " 'ordell': 57795,\n",
       " \"sturges'\": 40885,\n",
       " 'independentcritics': 52157,\n",
       " 'tempted': 5748,\n",
       " \"atkinson's\": 34727,\n",
       " 'hounded': 25250,\n",
       " 'apace': 52158,\n",
       " 'clicked': 15497,\n",
       " \"'humor'\": 30587,\n",
       " \"martino's\": 17180,\n",
       " \"'supporting\": 52159,\n",
       " 'warmongering': 52035,\n",
       " \"zemeckis's\": 34728,\n",
       " 'lube': 21914,\n",
       " 'shocky': 52160,\n",
       " 'plate': 7479,\n",
       " 'plata': 40886,\n",
       " 'sturgess': 40887,\n",
       " \"nerds'\": 40888,\n",
       " 'plato': 20603,\n",
       " 'plath': 34729,\n",
       " 'platt': 40889,\n",
       " 'mcnab': 52162,\n",
       " 'clumsiness': 27646,\n",
       " 'altogether': 3902,\n",
       " 'massacring': 42587,\n",
       " 'bicenntinial': 52163,\n",
       " 'skaal': 40890,\n",
       " 'droning': 14363,\n",
       " 'lds': 8779,\n",
       " 'jaguar': 21915,\n",
       " \"cale's\": 34730,\n",
       " 'nicely': 1780,\n",
       " 'mummy': 4591,\n",
       " \"lot's\": 18516,\n",
       " 'patch': 10089,\n",
       " 'kerkhof': 50205,\n",
       " \"leader's\": 52164,\n",
       " \"'movie\": 27647,\n",
       " 'uncomfirmed': 52165,\n",
       " 'heirloom': 40891,\n",
       " 'wrangle': 47363,\n",
       " 'emotion\\x85': 52166,\n",
       " \"'stargate'\": 52167,\n",
       " 'pinoy': 40892,\n",
       " 'conchatta': 40893,\n",
       " 'broeke': 41131,\n",
       " 'advisedly': 40894,\n",
       " \"barker's\": 17639,\n",
       " 'descours': 52169,\n",
       " 'lots': 775,\n",
       " 'lotr': 9262,\n",
       " 'irs': 9882,\n",
       " 'lott': 52170,\n",
       " 'xvi': 40895,\n",
       " 'irk': 34731,\n",
       " 'irl': 52171,\n",
       " 'ira': 6890,\n",
       " 'belzer': 21916,\n",
       " 'irc': 52172,\n",
       " 'ire': 27648,\n",
       " 'requisites': 40896,\n",
       " 'discipline': 7696,\n",
       " 'lyoko': 52964,\n",
       " 'extend': 11313,\n",
       " 'nature': 876,\n",
       " \"'dickie'\": 52173,\n",
       " 'optimist': 40897,\n",
       " 'lapping': 30589,\n",
       " 'superficial': 3903,\n",
       " 'vestment': 52174,\n",
       " 'extent': 2826,\n",
       " 'tendons': 52175,\n",
       " \"heller's\": 52176,\n",
       " 'quagmires': 52177,\n",
       " 'miyako': 52178,\n",
       " 'moocow': 20604,\n",
       " \"coles'\": 52179,\n",
       " 'lookit': 40898,\n",
       " 'ravenously': 52180,\n",
       " 'levitating': 40899,\n",
       " 'perfunctorily': 52181,\n",
       " 'lookin': 30590,\n",
       " \"lot'\": 40901,\n",
       " 'lookie': 52182,\n",
       " 'fearlessly': 34873,\n",
       " 'libyan': 52184,\n",
       " 'fondles': 40902,\n",
       " 'gopher': 35717,\n",
       " 'wearying': 40904,\n",
       " \"nz's\": 52185,\n",
       " 'minuses': 27649,\n",
       " 'puposelessly': 52186,\n",
       " 'shandling': 52187,\n",
       " 'decapitates': 31271,\n",
       " 'humming': 11932,\n",
       " \"'nother\": 40905,\n",
       " 'smackdown': 21917,\n",
       " 'underdone': 30591,\n",
       " 'frf': 40906,\n",
       " 'triviality': 52188,\n",
       " 'fro': 25251,\n",
       " 'bothers': 8780,\n",
       " \"'kensington\": 52189,\n",
       " 'much': 76,\n",
       " 'muco': 34733,\n",
       " 'wiseguy': 22618,\n",
       " \"richie's\": 27651,\n",
       " 'tonino': 40907,\n",
       " 'unleavened': 52190,\n",
       " 'fry': 11590,\n",
       " \"'tv'\": 40908,\n",
       " 'toning': 40909,\n",
       " 'obese': 14364,\n",
       " 'sensationalized': 30592,\n",
       " 'spiv': 40910,\n",
       " 'spit': 6262,\n",
       " 'arkin': 7367,\n",
       " 'charleton': 21918,\n",
       " 'jeon': 16826,\n",
       " 'boardroom': 21919,\n",
       " 'doubts': 4992,\n",
       " 'spin': 3087,\n",
       " 'hepo': 53086,\n",
       " 'wildcat': 27652,\n",
       " 'venoms': 10587,\n",
       " 'misconstrues': 52194,\n",
       " 'mesmerising': 18517,\n",
       " 'misconstrued': 40911,\n",
       " 'rescinds': 52195,\n",
       " 'prostrate': 52196,\n",
       " 'majid': 40912,\n",
       " 'climbed': 16482,\n",
       " 'canoeing': 34734,\n",
       " 'majin': 52198,\n",
       " 'animie': 57807,\n",
       " 'sylke': 40913,\n",
       " 'conditioned': 14902,\n",
       " 'waddell': 40914,\n",
       " '3\\x85': 52199,\n",
       " 'hyperdrive': 41191,\n",
       " 'conditioner': 34735,\n",
       " 'bricklayer': 53156,\n",
       " 'hong': 2579,\n",
       " 'memoriam': 52201,\n",
       " 'inventively': 30595,\n",
       " \"levant's\": 25252,\n",
       " 'portobello': 20641,\n",
       " 'remand': 52203,\n",
       " 'mummified': 19507,\n",
       " 'honk': 27653,\n",
       " 'spews': 19508,\n",
       " 'visitations': 40915,\n",
       " 'mummifies': 52204,\n",
       " 'cavanaugh': 25253,\n",
       " 'zeon': 23388,\n",
       " \"jungle's\": 40916,\n",
       " 'viertel': 34736,\n",
       " 'frenchmen': 27654,\n",
       " 'torpedoes': 52205,\n",
       " 'schlessinger': 52206,\n",
       " 'torpedoed': 34737,\n",
       " 'blister': 69879,\n",
       " 'cinefest': 52207,\n",
       " 'furlough': 34738,\n",
       " 'mainsequence': 52208,\n",
       " 'mentors': 40917,\n",
       " 'academic': 9097,\n",
       " 'stillness': 20605,\n",
       " 'academia': 40918,\n",
       " 'lonelier': 52209,\n",
       " 'nibby': 52210,\n",
       " \"losers'\": 52211,\n",
       " 'cineastes': 40919,\n",
       " 'corporate': 4452,\n",
       " 'massaging': 40920,\n",
       " 'bellow': 30596,\n",
       " 'absurdities': 19509,\n",
       " 'expetations': 53244,\n",
       " 'nyfiken': 40921,\n",
       " 'mehras': 75641,\n",
       " 'lasse': 52212,\n",
       " 'visability': 52213,\n",
       " 'militarily': 33949,\n",
       " \"elder'\": 52214,\n",
       " 'gainsbourg': 19026,\n",
       " 'hah': 20606,\n",
       " 'hai': 13423,\n",
       " 'haj': 34739,\n",
       " 'hak': 25254,\n",
       " 'hal': 4314,\n",
       " 'ham': 4895,\n",
       " 'duffer': 53262,\n",
       " 'haa': 52216,\n",
       " 'had': 69,\n",
       " 'advancement': 11933,\n",
       " 'hag': 16828,\n",
       " \"hand'\": 25255,\n",
       " 'hay': 13424,\n",
       " 'mcnamara': 20607,\n",
       " \"mozart's\": 52217,\n",
       " 'duffel': 30734,\n",
       " 'haq': 30597,\n",
       " 'har': 13890,\n",
       " 'has': 47,\n",
       " 'hat': 2404,\n",
       " 'hav': 40922,\n",
       " 'haw': 30598,\n",
       " 'figtings': 52218,\n",
       " 'elders': 15498,\n",
       " 'underpanted': 52219,\n",
       " 'pninson': 52220,\n",
       " 'unequivocally': 27655,\n",
       " \"barbara's\": 23676,\n",
       " \"bello'\": 52222,\n",
       " 'indicative': 13000,\n",
       " 'yawnfest': 40923,\n",
       " 'hexploitation': 52223,\n",
       " \"loder's\": 52224,\n",
       " 'sleuthing': 27656,\n",
       " \"justin's\": 32625,\n",
       " \"'ball\": 52225,\n",
       " \"'summer\": 52226,\n",
       " \"'demons'\": 34938,\n",
       " \"mormon's\": 52228,\n",
       " \"laughton's\": 34740,\n",
       " 'debell': 52229,\n",
       " 'shipyard': 39727,\n",
       " 'unabashedly': 30600,\n",
       " 'disks': 40404,\n",
       " 'crowd': 2293,\n",
       " 'crowe': 10090,\n",
       " \"vancouver's\": 56437,\n",
       " 'mosques': 34741,\n",
       " 'crown': 6630,\n",
       " 'culpas': 52230,\n",
       " 'crows': 27657,\n",
       " 'surrell': 53347,\n",
       " 'flowless': 52232,\n",
       " 'sheirk': 52233,\n",
       " \"'three\": 40926,\n",
       " \"peterson'\": 52234,\n",
       " 'ooverall': 52235,\n",
       " 'perchance': 40927,\n",
       " 'bottom': 1324,\n",
       " 'chabert': 53366,\n",
       " 'sneha': 52236,\n",
       " 'inhuman': 13891,\n",
       " 'ichii': 52237,\n",
       " 'ursla': 52238,\n",
       " 'completly': 30601,\n",
       " 'moviedom': 40928,\n",
       " 'raddick': 52239,\n",
       " 'brundage': 51998,\n",
       " 'brigades': 40929,\n",
       " 'starring': 1184,\n",
       " \"'goal'\": 52240,\n",
       " 'caskets': 52241,\n",
       " 'willcock': 52242,\n",
       " \"threesome's\": 52243,\n",
       " \"mosque'\": 52244,\n",
       " \"cover's\": 52245,\n",
       " 'spaceships': 17640,\n",
       " 'anomalous': 40930,\n",
       " 'ptsd': 27658,\n",
       " 'shirdan': 52246,\n",
       " 'obscenity': 21965,\n",
       " 'lemmings': 30602,\n",
       " 'duccio': 30603,\n",
       " \"levene's\": 52247,\n",
       " \"'gorby'\": 52248,\n",
       " \"teenager's\": 25258,\n",
       " 'marshall': 5343,\n",
       " 'honeymoon': 9098,\n",
       " 'shoots': 3234,\n",
       " 'despised': 12261,\n",
       " 'okabasho': 52249,\n",
       " 'fabric': 8292,\n",
       " 'cannavale': 18518,\n",
       " 'raped': 3540,\n",
       " \"tutt's\": 52250,\n",
       " 'grasping': 17641,\n",
       " 'despises': 18519,\n",
       " \"thief's\": 40931,\n",
       " 'rapes': 8929,\n",
       " 'raper': 52251,\n",
       " \"eyre'\": 27659,\n",
       " 'walchek': 52252,\n",
       " \"elmo's\": 23389,\n",
       " 'perfumes': 40932,\n",
       " 'spurting': 21921,\n",
       " \"exposition'\\x85\": 52253,\n",
       " 'denoting': 52254,\n",
       " 'thesaurus': 34743,\n",
       " \"shoot'\": 40933,\n",
       " 'bonejack': 49762,\n",
       " 'simpsonian': 52256,\n",
       " 'hebetude': 30604,\n",
       " \"hallow's\": 34744,\n",
       " 'desperation\\x85': 52257,\n",
       " 'incinerator': 34745,\n",
       " 'congratulations': 10311,\n",
       " 'humbled': 52258,\n",
       " \"else's\": 5927,\n",
       " 'trelkovski': 40848,\n",
       " \"rape'\": 52259,\n",
       " \"'chapters'\": 59389,\n",
       " '1600s': 52260,\n",
       " 'martian': 7256,\n",
       " 'nicest': 25259,\n",
       " 'eyred': 52262,\n",
       " 'passenger': 9460,\n",
       " 'disgrace': 6044,\n",
       " 'moderne': 52263,\n",
       " 'barrymore': 5123,\n",
       " 'yankovich': 52264,\n",
       " 'moderns': 40934,\n",
       " 'studliest': 52265,\n",
       " 'bedsheet': 52266,\n",
       " 'decapitation': 14903,\n",
       " 'slurring': 52267,\n",
       " \"'nunsploitation'\": 52268,\n",
       " \"'character'\": 34746,\n",
       " 'cambodia': 9883,\n",
       " 'rebelious': 52269,\n",
       " 'pasadena': 27660,\n",
       " 'crowne': 40935,\n",
       " \"'bedchamber\": 52270,\n",
       " 'conjectural': 52271,\n",
       " 'appologize': 52272,\n",
       " 'halfassing': 52273,\n",
       " 'paycheque': 57819,\n",
       " 'palms': 20609,\n",
       " \"'islands\": 52274,\n",
       " 'hawked': 40936,\n",
       " 'palme': 21922,\n",
       " 'conservatively': 40937,\n",
       " 'larp': 64010,\n",
       " 'palma': 5561,\n",
       " 'smelling': 21923,\n",
       " 'aragorn': 13001,\n",
       " 'hawker': 52275,\n",
       " 'hawkes': 52276,\n",
       " 'explosions': 3978,\n",
       " 'loren': 8062,\n",
       " \"pyle's\": 52277,\n",
       " 'shootout': 6707,\n",
       " \"mike's\": 18520,\n",
       " \"driscoll's\": 52278,\n",
       " 'cogsworth': 40938,\n",
       " \"britian's\": 52279,\n",
       " 'childs': 34747,\n",
       " \"portrait's\": 52280,\n",
       " 'chain': 3629,\n",
       " 'whoever': 2500,\n",
       " 'puttered': 52281,\n",
       " 'childe': 52282,\n",
       " 'maywether': 52283,\n",
       " 'chair': 3039,\n",
       " \"rance's\": 52284,\n",
       " 'machu': 34748,\n",
       " 'ballet': 4520,\n",
       " 'grapples': 34749,\n",
       " 'summerize': 76155,\n",
       " 'freelance': 30606,\n",
       " \"andrea's\": 52286,\n",
       " '\\x91very': 52287,\n",
       " 'coolidge': 45882,\n",
       " 'mache': 18521,\n",
       " 'balled': 52288,\n",
       " 'grappled': 40940,\n",
       " 'macha': 18522,\n",
       " 'underlining': 21924,\n",
       " 'macho': 5626,\n",
       " 'oversight': 19510,\n",
       " 'machi': 25260,\n",
       " 'verbally': 11314,\n",
       " 'tenacious': 21925,\n",
       " 'windshields': 40941,\n",
       " 'paychecks': 18560,\n",
       " 'jerk': 3399,\n",
       " \"good'\": 11934,\n",
       " 'prancer': 34751,\n",
       " 'prances': 21926,\n",
       " 'olympus': 52289,\n",
       " 'lark': 21927,\n",
       " 'embark': 10788,\n",
       " 'gloomy': 7368,\n",
       " 'jehaan': 52290,\n",
       " 'turaqui': 52291,\n",
       " \"child'\": 20610,\n",
       " 'locked': 2897,\n",
       " 'pranced': 52292,\n",
       " 'exact': 2591,\n",
       " 'unattuned': 52293,\n",
       " 'minute': 786,\n",
       " 'skewed': 16121,\n",
       " 'hodgins': 40943,\n",
       " 'skewer': 34752,\n",
       " 'think\\x85': 52294,\n",
       " 'rosenstein': 38768,\n",
       " 'helmit': 52295,\n",
       " 'wrestlemanias': 34753,\n",
       " 'hindered': 16829,\n",
       " \"martha's\": 30607,\n",
       " 'cheree': 52296,\n",
       " \"pluckin'\": 52297,\n",
       " 'ogles': 40944,\n",
       " 'heavyweight': 11935,\n",
       " 'aada': 82193,\n",
       " 'chopping': 11315,\n",
       " 'strongboy': 61537,\n",
       " 'hegemonic': 41345,\n",
       " 'adorns': 40945,\n",
       " 'xxth': 41349,\n",
       " 'nobuhiro': 34754,\n",
       " 'capitães': 52301,\n",
       " 'kavogianni': 52302,\n",
       " 'antwerp': 13425,\n",
       " 'celebrated': 6541,\n",
       " 'roarke': 52303,\n",
       " 'baggins': 40946,\n",
       " 'cheeseburgers': 31273,\n",
       " 'matras': 52304,\n",
       " \"nineties'\": 52305,\n",
       " \"'craig'\": 52306,\n",
       " 'celebrates': 13002,\n",
       " 'unintentionally': 3386,\n",
       " 'drafted': 14365,\n",
       " 'climby': 52307,\n",
       " '303': 52308,\n",
       " 'oldies': 18523,\n",
       " 'climbs': 9099,\n",
       " 'honour': 9658,\n",
       " 'plucking': 34755,\n",
       " '305': 30077,\n",
       " 'address': 5517,\n",
       " 'menjou': 40947,\n",
       " \"'freak'\": 42595,\n",
       " 'dwindling': 19511,\n",
       " 'benson': 9461,\n",
       " 'white’s': 52310,\n",
       " 'shamelessness': 40948,\n",
       " 'impacted': 21928,\n",
       " 'upatz': 52311,\n",
       " 'cusack': 3843,\n",
       " \"flavia's\": 37570,\n",
       " 'effette': 52312,\n",
       " 'influx': 34756,\n",
       " 'boooooooo': 52313,\n",
       " 'dimitrova': 52314,\n",
       " 'houseman': 13426,\n",
       " 'bigas': 25262,\n",
       " 'boylen': 52315,\n",
       " 'phillipenes': 52316,\n",
       " 'fakery': 40949,\n",
       " \"grandpa's\": 27661,\n",
       " 'darnell': 27662,\n",
       " 'undergone': 19512,\n",
       " 'handbags': 52318,\n",
       " 'perished': 21929,\n",
       " 'pooped': 37781,\n",
       " 'vigour': 27663,\n",
       " 'opposed': 3630,\n",
       " 'etude': 52319,\n",
       " \"caine's\": 11802,\n",
       " 'doozers': 52320,\n",
       " 'photojournals': 34757,\n",
       " 'perishes': 52321,\n",
       " 'constrains': 34758,\n",
       " 'migenes': 40951,\n",
       " 'consoled': 30608,\n",
       " 'alastair': 16830,\n",
       " 'wvs': 52322,\n",
       " 'ooooooh': 52323,\n",
       " 'approving': 34759,\n",
       " 'consoles': 40952,\n",
       " 'disparagement': 52067,\n",
       " 'futureistic': 52325,\n",
       " 'rebounding': 52326,\n",
       " \"'date\": 52327,\n",
       " 'gregoire': 52328,\n",
       " 'rutherford': 21930,\n",
       " 'americanised': 34760,\n",
       " 'novikov': 82199,\n",
       " 'following': 1045,\n",
       " 'munroe': 34761,\n",
       " \"morita'\": 52329,\n",
       " 'christenssen': 52330,\n",
       " 'oatmeal': 23109,\n",
       " 'fossey': 25263,\n",
       " 'livered': 40953,\n",
       " 'listens': 13003,\n",
       " \"'marci\": 76167,\n",
       " \"otis's\": 52333,\n",
       " 'thanking': 23390,\n",
       " 'maude': 16022,\n",
       " 'extensions': 34762,\n",
       " 'ameteurish': 52335,\n",
       " \"commender's\": 52336,\n",
       " 'agricultural': 27664,\n",
       " 'convincingly': 4521,\n",
       " 'fueled': 17642,\n",
       " 'mahattan': 54017,\n",
       " \"paris's\": 40955,\n",
       " 'vulkan': 52339,\n",
       " 'stapes': 52340,\n",
       " 'odysessy': 52341,\n",
       " 'harmon': 12262,\n",
       " 'surfing': 4255,\n",
       " 'halloran': 23497,\n",
       " 'unbelieveably': 49583,\n",
       " \"'offed'\": 52342,\n",
       " 'quadrant': 30610,\n",
       " 'inhabiting': 19513,\n",
       " 'nebbish': 34763,\n",
       " 'forebears': 40956,\n",
       " 'skirmish': 34764,\n",
       " 'ocassionally': 52343,\n",
       " \"'resist\": 52344,\n",
       " 'impactful': 21931,\n",
       " 'spicier': 52345,\n",
       " 'touristy': 40957,\n",
       " \"'football'\": 52346,\n",
       " 'webpage': 40958,\n",
       " 'exurbia': 52348,\n",
       " 'jucier': 52349,\n",
       " 'professors': 14904,\n",
       " 'structuring': 34765,\n",
       " 'jig': 30611,\n",
       " 'overlord': 40959,\n",
       " 'disconnect': 25264,\n",
       " 'sniffle': 82204,\n",
       " 'slimeball': 40960,\n",
       " 'jia': 40961,\n",
       " 'milked': 16831,\n",
       " 'banjoes': 40962,\n",
       " 'jim': 1240,\n",
       " 'workforces': 52351,\n",
       " 'jip': 52352,\n",
       " 'rotweiller': 52353,\n",
       " 'mundaneness': 34766,\n",
       " \"'ninja'\": 52354,\n",
       " \"dead'\": 11043,\n",
       " \"cipriani's\": 40963,\n",
       " 'modestly': 20611,\n",
       " \"professor'\": 52355,\n",
       " 'shacked': 40964,\n",
       " 'bashful': 34767,\n",
       " 'sorter': 23391,\n",
       " 'overpowering': 16123,\n",
       " 'workmanlike': 18524,\n",
       " 'henpecked': 27665,\n",
       " 'sorted': 18525,\n",
       " \"jōb's\": 52357,\n",
       " \"'always\": 52358,\n",
       " \"'baptists\": 34768,\n",
       " 'dreamcatchers': 52359,\n",
       " \"'silence'\": 52360,\n",
       " 'hickory': 21932,\n",
       " 'fun\\x97yet': 52361,\n",
       " 'breakumentary': 52362,\n",
       " 'didn': 15499,\n",
       " 'didi': 52363,\n",
       " 'pealing': 52364,\n",
       " 'dispite': 40965,\n",
       " \"italy's\": 25265,\n",
       " 'instability': 21933,\n",
       " 'quarter': 6542,\n",
       " 'quartet': 12611,\n",
       " 'padmé': 52365,\n",
       " \"'bleedmedry\": 52366,\n",
       " 'pahalniuk': 52367,\n",
       " 'honduras': 52368,\n",
       " 'bursting': 10789,\n",
       " \"pablo's\": 41468,\n",
       " 'irremediably': 52370,\n",
       " 'presages': 40966,\n",
       " 'bowlegged': 57835,\n",
       " 'dalip': 65186,\n",
       " 'entering': 6263,\n",
       " 'newsradio': 76175,\n",
       " 'presaged': 54153,\n",
       " \"giallo's\": 27666,\n",
       " 'bouyant': 40967,\n",
       " 'amerterish': 52371,\n",
       " 'rajni': 18526,\n",
       " 'leeves': 30613,\n",
       " 'macauley': 34770,\n",
       " 'seriously': 615,\n",
       " 'sugercoma': 52372,\n",
       " 'grimstead': 52373,\n",
       " \"'fairy'\": 52374,\n",
       " 'zenda': 30614,\n",
       " \"'twins'\": 52375,\n",
       " 'realisation': 17643,\n",
       " 'highsmith': 27667,\n",
       " 'raunchy': 7820,\n",
       " 'incentives': 40968,\n",
       " 'flatson': 52377,\n",
       " 'snooker': 35100,\n",
       " 'crazies': 16832,\n",
       " 'crazier': 14905,\n",
       " 'grandma': 7097,\n",
       " 'napunsaktha': 52378,\n",
       " 'workmanship': 30615,\n",
       " 'reisner': 52379,\n",
       " \"sanford's\": 61309,\n",
       " '\\x91doña': 52380,\n",
       " 'modest': 6111,\n",
       " \"everything's\": 19156,\n",
       " 'hamer': 40969,\n",
       " \"couldn't'\": 52382,\n",
       " 'quibble': 13004,\n",
       " 'socking': 52383,\n",
       " 'tingler': 21934,\n",
       " 'gutman': 52384,\n",
       " 'lachlan': 40970,\n",
       " 'tableaus': 52385,\n",
       " 'headbanger': 52386,\n",
       " 'spoken': 2850,\n",
       " 'cerebrally': 34771,\n",
       " \"'road\": 23493,\n",
       " 'tableaux': 21935,\n",
       " \"proust's\": 40971,\n",
       " 'periodical': 40972,\n",
       " \"shoveller's\": 52388,\n",
       " 'tamara': 25266,\n",
       " 'affords': 17644,\n",
       " 'concert': 3252,\n",
       " \"yara's\": 87958,\n",
       " 'someome': 52389,\n",
       " 'lingering': 8427,\n",
       " \"abraham's\": 41514,\n",
       " 'beesley': 34772,\n",
       " 'cherbourg': 34773,\n",
       " 'kagan': 28627,\n",
       " 'snatch': 9100,\n",
       " \"miyazaki's\": 9263,\n",
       " 'absorbs': 25267,\n",
       " \"koltai's\": 40973,\n",
       " 'tingled': 64030,\n",
       " 'crossroads': 19514,\n",
       " 'rehab': 16124,\n",
       " 'falworth': 52392,\n",
       " 'sequals': 52393,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index  # Dictionary Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "smqtJx1U2RQQ",
    "outputId": "8545c4e6-c798-40b7-a3b2-48616444b05d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fawn</td>\n",
       "      <td>34704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tsukino</td>\n",
       "      <td>52009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunnery</td>\n",
       "      <td>52010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sonja</td>\n",
       "      <td>16819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vani</td>\n",
       "      <td>63954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88583</th>\n",
       "      <td>expands</td>\n",
       "      <td>20600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88584</th>\n",
       "      <td>&lt;PAD&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88585</th>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88586</th>\n",
       "      <td>&lt;UNKNOWN&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88587</th>\n",
       "      <td>&lt;UNUSED&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88588 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Words  Indices\n",
       "0           fawn    34704\n",
       "1        tsukino    52009\n",
       "2        nunnery    52010\n",
       "3          sonja    16819\n",
       "4           vani    63954\n",
       "...          ...      ...\n",
       "88583    expands    20600\n",
       "88584      <PAD>        0\n",
       "88585    <START>        1\n",
       "88586  <UNKNOWN>        2\n",
       "88587   <UNUSED>        3\n",
       "\n",
       "[88588 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df3 = pd.DataFrame(list(word_index.items()),columns = ['Words','Indices']) \n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "Ij0ZUj-R9-ys",
    "outputId": "05cc368a-d578-4c19-f799-06932f327802"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indices</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34704</td>\n",
       "      <td>fawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52009</td>\n",
       "      <td>tsukino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52010</td>\n",
       "      <td>nunnery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16819</td>\n",
       "      <td>sonja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63954</td>\n",
       "      <td>vani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88583</th>\n",
       "      <td>20600</td>\n",
       "      <td>expands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88584</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;PAD&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88585</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88586</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;UNKNOWN&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88587</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;UNUSED&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88588 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Indices      Words\n",
       "0        34704       fawn\n",
       "1        52009    tsukino\n",
       "2        52010    nunnery\n",
       "3        16819      sonja\n",
       "4        63954       vani\n",
       "...        ...        ...\n",
       "88583    20600    expands\n",
       "88584        0      <PAD>\n",
       "88585        1    <START>\n",
       "88586        2  <UNKNOWN>\n",
       "88587        3   <UNUSED>\n",
       "\n",
       "[88588 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df4 = pd.DataFrame(reverse_word_index.items(), columns=[\"Indices\", \"Words\"])\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFXK-g6G81sC"
   },
   "source": [
    "## Data Insight\n",
    "\n",
    "Here we take a closer look at our data. How many words do our reviews contain?\n",
    "\n",
    "And what do our review look like in machine and human readable form?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yD1qHVBn81Y_",
    "outputId": "488daadb-4976-4f6f-91d7-8fdc7fb0f7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 2494\n",
      "Minimum review length: 7\n",
      "Mean review length: 234.75892\n",
      "\n",
      "Machine readable Review\n",
      "  Review Text: [1, 13, 219, 14, 33, 4, 2, 22, 1413, 12, 16, 373, 175, 2711, 1115, 1026, 430, 939, 16, 23, 2444, 25, 43, 697, 89, 12, 16, 170, 8, 130, 262, 19, 32, 4, 665, 7, 4, 2, 322, 5, 4, 1520, 7, 4, 86, 250, 10, 10, 4, 249, 173, 16, 4, 3891, 6, 19, 4, 167, 564, 5, 564, 1325, 36, 805, 8, 216, 638, 17, 2, 21, 25, 100, 376, 507, 4, 2110, 15, 79, 125, 23, 567, 13, 2134, 233, 36, 4852, 2, 5, 81, 1672, 10, 10, 92, 437, 129, 58, 13, 69, 8, 401, 61, 1432, 39, 1286, 46, 7, 12]\n",
      "  Review Sentiment: 0\n",
      "\n",
      "Human Readable Review\n",
      "  Review Text: <START> i saw this at the <UNKNOWN> film festival it was awful every clichéd violent rich boy fantasy was on display you just knew how it was going to end especially with all the shots of the <UNKNOWN> wife and the rape of the first girl br br the worst part was the q a with the director writer and writer producer they tried to come across as <UNKNOWN> but you could tell they're the types that get off on violence i bet anything they frequent <UNKNOWN> and do drugs br br don't waste your time i had to keep my boyfriend from walking out of it\n",
      "  Review Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Concatonate test and training datasets\n",
    "allreviews = np.concatenate((x_train, x_test), axis=0)\n",
    "\n",
    "# Review lengths across test and training whole datasets\n",
    "print(\"Maximum review length: {}\".format(len(max((allreviews), key=len))))\n",
    "print(\"Minimum review length: {}\".format(len(min((allreviews), key=len))))\n",
    "result = [len(x) for x in allreviews]\n",
    "print(\"Mean review length: {}\".format(np.mean(result)))\n",
    "\n",
    "# Print a review and it's class as stored in the dataset. Replace the number\n",
    "# to select a different review.\n",
    "print(\"\")\n",
    "print(\"Machine readable Review\")\n",
    "print(\"  Review Text: \" + str(x_train[60]))\n",
    "print(\"  Review Sentiment: \" + str(y_train[60]))\n",
    "\n",
    "# Print a review and it's class in human readable format. Replace the number\n",
    "# to select a different review.\n",
    "print(\"\")\n",
    "print(\"Human Readable Review\")\n",
    "print(\"  Review Text: \" + decode_review(x_train[60]))\n",
    "print(\"  Review Sentiment: \" + class_names[y_train[60]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mF-Votm66zD5"
   },
   "source": [
    "## Pre-processing Data\n",
    "\n",
    "We need to make sure that our reviews are of a uniform length. This is for the LSTM's parameters.\n",
    "\n",
    "Some reviews will need to be truncated, while others need to be padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNtJTLJA6gaT",
    "outputId": "59540239-44b9-42a5-b476-e3fe417ffe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Training Review Data: (25000, 500)\n",
      "Shape Training Class Data: (25000,)\n",
      "Shape Test Review Data: (25000, 500)\n",
      "Shape Test Class Data: (25000,)\n",
      "\n",
      "Human Readable Review Text (post padding): <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> i saw this at the <UNKNOWN> film festival it was awful every clichéd violent rich boy fantasy was on display you just knew how it was going to end especially with all the shots of the <UNKNOWN> wife and the rape of the first girl br br the worst part was the q a with the director writer and writer producer they tried to come across as <UNKNOWN> but you could tell they're the types that get off on violence i bet anything they frequent <UNKNOWN> and do drugs br br don't waste your time i had to keep my boyfriend from walking out of it\n"
     ]
    }
   ],
   "source": [
    "# The length of reviews\n",
    "review_length = 500\n",
    "\n",
    "# Padding / truncated our reviews\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = review_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = review_length)\n",
    "\n",
    "# Check the size of our datasets. Review data for both test and training should \n",
    "# contain 25000 reviews of 500 integers. Class data should contain 25000 values, \n",
    "# one for each review. Class values are 0 or 1, indicating a negative \n",
    "# or positive review.\n",
    "print(\"Shape Training Review Data: \" + str(x_train.shape))\n",
    "print(\"Shape Training Class Data: \" + str(y_train.shape))\n",
    "print(\"Shape Test Review Data: \" + str(x_test.shape))\n",
    "print(\"Shape Test Class Data: \" + str(y_test.shape))\n",
    "\n",
    "# Note padding is added to start of review, not the end\n",
    "print(\"\")\n",
    "print(\"Human Readable Review Text (post padding): \" + decode_review(x_train[60]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfOdV_VCCFee"
   },
   "source": [
    "## Create and build LSTM Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nmO8M4aCKwT",
    "outputId": "66ea8d2f-de38-4f11-d687-ed6e8f0e82b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           320000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We begin by defining the a empty stack. We'll use this for building our \n",
    "# network, later by layer.\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# The Embedding Layer provides a spatial mapping (or Word Embedding) of all the \n",
    "# individual words in our training set. Words close to one another share context \n",
    "# and or meaning. This spatial mapping is learning during the training process.\n",
    "model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim = vocab_size, # The size of our vocabulary \n",
    "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
    "        input_length = review_length # Length of input sequences\n",
    "    )\n",
    ")\n",
    "\n",
    "# Dropout layers fight overfitting and forces the model to learn multiple \n",
    "# representations of the same data by randomly disabling neurons in the \n",
    "# learning phase.\n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.25 # Randomly disable 25% of neurons\n",
    "    )\n",
    ")\n",
    "\n",
    "# We are using a fast version of LSTM whih is optimised for GPUs. This layer \n",
    "# looks at the sequence of words in the review, along with their word embeddings\n",
    "# and uses both of these to determine to sentiment of a given review.\n",
    "model.add(\n",
    "    tf.keras.layers.LSTM(\n",
    "        units=32 # 32 LSTM units in this layer\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add a second dropout layer with the same aim as the first.\n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.25 # Randomly disable 25% of neurons\n",
    "    )\n",
    ")\n",
    "\n",
    "# All LSTM units are connected to a single node in the dense layer. A sigmoid \n",
    "# activation function determines the output from this node - a value \n",
    "# between 0 and 1. Closer to 0 indicates a negative review. Closer to 1 \n",
    "# indicates a positive review.\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=1, # Single unit\n",
    "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
    "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
    "    metrics=['accuracy']) # reporting metric\n",
    "\n",
    "# Display a summary of the models structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xx1Q2I8WNI9"
   },
   "source": [
    "## Visualise the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "cz0Erj2WU3Vh",
    "outputId": "3dddbe63-26e4-4a52-a45f-08cd6a386b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KdfAoHsGwzo"
   },
   "source": [
    "## Train the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEN1vV4nG1V3",
    "outputId": "d2365861-f545-49ef-bb4a-da1a2e4ed312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "79/79 [==============================] - 65s 800ms/step - loss: 0.6159 - accuracy: 0.6694 - val_loss: 0.4286 - val_accuracy: 0.8412\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 62s 784ms/step - loss: 0.3772 - accuracy: 0.8507 - val_loss: 0.3225 - val_accuracy: 0.8696\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 63s 796ms/step - loss: 0.2427 - accuracy: 0.9118 - val_loss: 0.2955 - val_accuracy: 0.8818\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM on the training data\n",
    "history = model.fit(\n",
    "\n",
    "    # Training data : features (review) and classes (positive or negative)\n",
    "    x_train, y_train,\n",
    "                    \n",
    "    # Number of samples to work through before updating the \n",
    "    # internal model parameters via back propagation. The \n",
    "    # higher the batch, the more memory you need.\n",
    "    batch_size=256, \n",
    "\n",
    "    # An epoch is an iteration over the entire training data.\n",
    "    epochs=3, \n",
    "    \n",
    "    # The model will set apart his fraction of the training \n",
    "    # data, will not train on it, and will evaluate the loss\n",
    "    # and any model metrics on this data at the end of \n",
    "    # each epoch.\n",
    "    validation_split=0.2,\n",
    "    \n",
    "    verbose=1\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpCS2-jFH1KY"
   },
   "source": [
    "## Evaluate model with test data and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "nPnfxwbnITqV",
    "outputId": "08493db5-a14a-40aa-cdf4-33b46b6b68d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pythonProject\\Internship\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.82      0.87     12500\n",
      "    Positive       0.84      0.92      0.88     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.88      0.87      0.87     25000\n",
      "weighted avg       0.88      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Model Predictions for test data\n",
    "from sklearn.metrics import classification_report\n",
    "predicted_classes = model.predict_classes(x_test)\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkfHCIVHrJni"
   },
   "source": [
    "## View some incorrect predictions\n",
    "\n",
    "Lets have a look at some of the incorrectly classified reviews. For readability we remove the padding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bwKLBwBbp7zg",
    "outputId": "edd92930-4ee3-4f98-e2bf-2b1684498954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrectly classified Test Review [1]\n",
      "Test Review #8: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> hollywood had a long love affair with bogus <UNKNOWN> nights tales but few of these products have stood the test of time the most memorable were the jon hall maria <UNKNOWN> films which have long since become camp this one is filled with dubbed songs <UNKNOWN> <UNKNOWN> and slapstick it's a truly crop of corn and pretty near <UNKNOWN> today it was nominated for its imaginative special effects which are almost <UNKNOWN> in this day and age <UNKNOWN> mainly of trick photography the only outstanding positive feature which survives is its beautiful color and clarity sad to say of the many films made in this genre few of them come up to alexander <UNKNOWN> original thief of <UNKNOWN> almost any other <UNKNOWN> nights film is superior to this one though it's a loser\n",
      "\n",
      "Incorrectly classified Test Review [2]\n",
      "Test Review #17: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> ed <UNKNOWN> mitchell is a teenager who lives for his job at good <UNKNOWN> a small but friendly neighborhood <UNKNOWN> stand while his buddy <UNKNOWN> thompson also works there but lack <UNKNOWN> single minded devotion to his job he's there because he accidentally destroyed the car of his teacher mr <UNKNOWN> <UNKNOWN> and has to raise money to pay the <UNKNOWN> when <UNKNOWN> <UNKNOWN> a <UNKNOWN> fast foot chain opens across the street it looks like good <UNKNOWN> is history until ed <UNKNOWN> a secret <UNKNOWN> that brings hundreds of new customers to their door however the <UNKNOWN> manager of <UNKNOWN> <UNKNOWN> kurt jan is determined to get his hands on the <UNKNOWN> and put good <UNKNOWN> out of business meanwhile ed and <UNKNOWN> must rescue <UNKNOWN> <UNKNOWN> <UNKNOWN> the world's oldest fast food employee from the demented hills asylum and ed might just find love with <UNKNOWN> jackson if he could take his mind off the <UNKNOWN> long enough to pay attention to her good <UNKNOWN> is a comedy directed for kids decent story acting and overall a pretty harmless kids movie\n",
      "\n",
      "Incorrectly classified Test Review [3]\n",
      "Test Review #22: Predicted [Negative] Actual [Positive]\n",
      "Test Review Text: <START> how managed to avoid attention remains a mystery a potent mix of comedy and crime this one takes chances where tarantino plays it safe with the hollywood formula the risks don't always pay off one character in one sequence comes off <UNKNOWN> silly and falls flat in the lead role thomas jane gives a wonderful and complex performance and two brief appearances by mickey rourke hint at the high potential of this much under and <UNKNOWN> used actor here's a director one should keep one's eye on\n",
      "\n",
      "Incorrectly classified Test Review [4]\n",
      "Test Review #32: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> if you have never read the classic science fiction novel this mini series is based on it may actually be good unfortunately if you are a fan of the book you probably won't be able to watch more than the first hour or two all of the political intrigue has been taken out of the film the most important scenes from the book have been taken out characters motivations have been changed completely and words from the wrong characters mouths where in the novel paul was a teen age boy with incredible political skill and a great understanding of the way the world worked in this film he is hot headed and and frustrated avoid this movie at all costs\n",
      "\n",
      "Incorrectly classified Test Review [5]\n",
      "Test Review #59: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> oh how awfully this movie is i don't know if it is a horror film or a drama cause the story and the both genres are not established very well the story is not moving it is slow boring and sleepy from the beginning to end this movie really <UNKNOWN> me but i really liked the camera work it is authentic fresh and clear the acting is great too the little boy was the great performer in this movie but it hasn't made me to jump from my seat but this movie makes me grab a <UNKNOWN> lay on the bed and sleep until the credits roll br br boring not worth watching i tell you this movie sucked br br 1 10\n",
      "\n",
      "Incorrectly classified Test Review [6]\n",
      "Test Review #66: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: forgive me if i don't phrase this correctly i was extremely disappointed that there were no optimistic overtones at all yes we all know that life is full of hard stuff and yes we know that things such as incest do occur but i really find it hard to applaud a movie that has not one piece of joy in it i believe that a director has a responsibility to put it in there somewhere otherwise the movie is all about them and their feelings they have created it for themselves not for an audience br br which i think is the basis of why this movie isn't so great the special features mention that the director wrote the screenplay in a <UNKNOWN> hour sitting the day after he himself tried to end his own life well it may have been <UNKNOWN> for him to do this however the movie <UNKNOWN> of self <UNKNOWN> when you know the story behind why it was written i feel horrid i'm going to write a movie about feeling horrid note i have read the interview with andrew urban and understand why needed to write something to help him through his own issues but i believe there is a line in film that cannot be crossed the line of making a movie purely for your own emotional needs and i feel that this is what has unintentionally happened here br br by his own admission the director had no technical experience at all and sadly this makes the movie come off looking like nothing more than a year twelve media project br br as for any <UNKNOWN> that this movie should be studied at school or that all teenagers should watch it not sure there either because there is a very dangerous line at the end i too have been in a place where i have thought that someone who no longer has to <UNKNOWN> <UNKNOWN> is <UNKNOWN> but as an adult i do worry that this line could be influential on a young viewer that was in a vulnerable frame of mind might be in there to promote discussion but again it reflects no possibility of redemption or joy in this story as a whole in fact it almost <UNKNOWN> that there is more sadness to come br br i haven't seen elephant but i just might go find it given all the comparisons here br br nothing personal here guys i do hope you can make another movie someday and we all have to start out somewhere so forgive me if i've been too harsh i am glad that you are proud of what you created which in the end is what life is all about it's not a movie i would recommend though br br oh i did like the way the time frames often <UNKNOWN> thought that was an interesting way to film br br but the whole its the quiet ones you have to watch we already know that\n",
      "\n",
      "Incorrectly classified Test Review [7]\n",
      "Test Review #75: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> the adventures of <UNKNOWN> has to be one of the <UNKNOWN> excuses for a movie i've yet run across you would have to look far and wide to find anything that approaches the level of <UNKNOWN> on display in this movie acting  bad editing  bad direction  bad special effects  bad and laughable plot  bad lighting  bad cinematography  bad costume design  bad and silly everything else  bad watching the adventures of <UNKNOWN> is about as enjoyable as a root <UNKNOWN> even for a fan of bad movies it's a real <UNKNOWN> test this is one for either <UNKNOWN> or lou <UNKNOWN> <UNKNOWN> if any exist br br eight things i learned from watching the adventures of <UNKNOWN> br br 1 if you don't have the budget for real special effects <UNKNOWN> a scene from the previous movie it will look great trust me br br 2 when on a quest to recover take time for frequent stops to oil up you body it worked for <UNKNOWN> and his two amazon companions br br 3 any sword fight use of magic and just about all other day to day activities in ancient <UNKNOWN> created a sound very similar to a game of man or <UNKNOWN> br br 4 some of the ancient greek gods dressed like extras from star wars br br 5 if you need to pad your crappy movie's runtime <UNKNOWN> the title sequence by adding star trek style credits and throw in some overly <UNKNOWN> music it also helps if you've got a previous movie to pull scenes from br br 6 fight scenes move along much <UNKNOWN> if the bad guys attack <UNKNOWN> one at a time br br 7 william <UNKNOWN> did anything for money br br 8 i didn't think it was possible but the adventures of <UNKNOWN> makes the first film <UNKNOWN> 1983 look like an academy award winner\n",
      "\n",
      "Incorrectly classified Test Review [8]\n",
      "Test Review #78: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> there seems to be a spectrum of cinema on the left there are movies made mostly for entertainment and or commercial purposes in the middle there are movies that are both entertaining and artistic on the right are movies that are not as commercial but are focused more on cinema as art than cinema as product br br i'm not here to say any one part of the spectrum is better than any other but that when a movie goes too far to either end it's rarely good such is the case with <UNKNOWN> br br i had no idea what to expect when i saw it advertised a few friends were going and asked if i wanted to come along none of us knew what to expect and by the end none of us were pleased br br yes there are breathtaking images yes i'm amazed at the <UNKNOWN> the filmmakers went to in searching through <UNKNOWN> footage yes the soundtrack is enjoyable to listen to and probably the best part of the experience the thing is this goes so far to the right side of the spectrum i mentioned that i can't say anything nice about the movie as a whole br br it's preachy it's a <UNKNOWN> of symbolism and obvious morality it's not saying anything new or forcing the viewer to examine life in a new way it's just telling us things we already know that is if we can even figure out what it's saying br br this movie is simply art for <UNKNOWN> sake an attempt to say look at how deep and thought provoking we can be by using montage when a film becomes more about how clever or intelligent its creators are than about its subject it <UNKNOWN> to be a film and simply becomes celluloid self <UNKNOWN>\n",
      "\n",
      "Incorrectly classified Test Review [9]\n",
      "Test Review #80: Predicted [Negative] Actual [Positive]\n",
      "Test Review Text: <START> with the obvious exception of fools horses this was in my opinion david <UNKNOWN> finest series br br coming straight after his tv debut on <UNKNOWN> not <UNKNOWN> your set ' these 13 episodes revealed a <UNKNOWN> of comic timing not seen since the old silent movie days by comparison <UNKNOWN> open all hours and that awful series <UNKNOWN> man' did not come close br br i believe jason banned the series being repeated because it showed him at his <UNKNOWN> shame on him a new generation deserves to enjoy this the series actually <UNKNOWN> in the ratings but that is most likely because it was shown against 'the <UNKNOWN> which aired on bbc at the same time before <UNKNOWN> were <UNKNOWN> br br btw i have only just noticed that his long suffering assistant spencer was played by mark <UNKNOWN> alan <UNKNOWN> off <UNKNOWN> street i am amazed he didn't try to murder edgar <UNKNOWN>\n",
      "\n",
      "Incorrectly classified Test Review [10]\n",
      "Test Review #81: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> <UNKNOWN> the tv movie <UNKNOWN> a very twisted and version of the story about the greek superhero paul makes a good attempt to play this hero sean <UNKNOWN> <UNKNOWN> his sam image by playing <UNKNOWN> a thrown in character to make the whole thing a buddy movie picture i almost expected his to say at one point we're in a bad situation mr <UNKNOWN> uh i mean <UNKNOWN> an unexpected good performance comes from timothy dalton one of the lesser james bonds as father love interest looks like paris hilton something which just turned me off right away someone has twisted and the original story into somewhat of a murky and sometimes incomprehensible story the special effects don't help either while the <UNKNOWN> scene does the original story justice the lion and <UNKNOWN> are just well lame i believe the creatures and effects from power rangers <UNKNOWN> across my mind at least twice and the golden <UNKNOWN> felt rushed and very computer generated and they took out one of my favorite parts of what was originally a very cool story the movie can't decide whether it's greek roman or american and it almost ruined the original story a classic epic don't bother looking for this one on the direct to dvd c\n",
      "\n",
      "Incorrectly classified Test Review [11]\n",
      "Test Review #100: Predicted [Negative] Actual [Positive]\n",
      "Test Review Text: <START> a quick glance at the premise of this film would seem to indicate just another dumb <UNKNOWN> <UNKNOWN> <UNKNOWN> slash fest the type where sex equals death and the actors are all annoying stereotypes you actually want to die however delivers considerably more br br rather than focus on bare flesh and gore though there is a little of each no sex however the flick focuses on delivering impending dread <UNKNOWN> tension amidst a lovely <UNKNOWN> backdrop these feelings are further <UNKNOWN> by a cast of realistically likable characters and <UNKNOWN> that are more amoral than cardboard <UNKNOWN> of evil oh yeah george kennedy is here too and when is that not a good thing br br if you liked wrong turn then watch this to see where much of its' <UNKNOWN> came from\n",
      "\n",
      "Incorrectly classified Test Review [12]\n",
      "Test Review #101: Predicted [Negative] Actual [Positive]\n",
      "Test Review Text: <START> <UNKNOWN> is the first of its kind in turkish cinema and it's way better than i expected those people who say it's neither scary nor funny have a point it's not all that great indeed but it must be kept in mind that everyone involved with the movie is rather amateur so it's basically a maiden voyage and comparing this one to other films such as the 1st class garbage propaganda this movie is pretty damn good br br one thing that must be said it deals with the <UNKNOWN> <UNKNOWN> life in turkey very realistically that's exactly how it goes the scenes that are meant to scare are somewhat cheap and <UNKNOWN> most of them even if not all but that religion lesson scene made me laugh in tears and performs the best acting of this flick as a religion teacher br br it's not a waste of your time go and watch it you'll find it rather amusing especially if you know turkey enough to relate to turkish school lives\n",
      "\n",
      "Incorrectly classified Test Review [13]\n",
      "Test Review #112: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> if you want to see a horror film which is horrible and in very bad taste this is definitely the film to view this films starts out with two young teenagers getting wild ideas about going into a chat room and going out on blind dates and quite possibly they will wind up like a little <UNKNOWN> to the slaughter house plenty of blood gore nudity <UNKNOWN> and all kinds of blood <UNKNOWN> <UNKNOWN> and things you will never dream a person is capable of performing on men and women if you like <UNKNOWN> well this kind of <UNKNOWN> deals with heavy heavy <UNKNOWN> and plenty of besides lots of <UNKNOWN> and thread to seal up things on the human body i really hope that this film does not give some sick person in this world the idea to act out these horrors in real life\n",
      "\n",
      "Incorrectly classified Test Review [14]\n",
      "Test Review #115: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> while the design and locations and photography are strong <UNKNOWN> in this film it is a turgid and melodramatic affair which demonstrates the limits of cinema to convey truth br br the case is the use of the soundtrack music a mix of <UNKNOWN> and andrew lloyd <UNKNOWN> that plays constantly and <UNKNOWN> and would have made max <UNKNOWN> <UNKNOWN> at its over use as it <UNKNOWN> the audience how difficult how <UNKNOWN> how tortured it is to be an artist and then it really counts the story the details at the end br br this <UNKNOWN> and <UNKNOWN> exploitation of emotions was once well <UNKNOWN> by peter <UNKNOWN> about a <UNKNOWN> <UNKNOWN> book this is not writing this is barbara <UNKNOWN> precisely the same critique can be made of this film a <UNKNOWN> <UNKNOWN> vanity project\n",
      "\n",
      "Incorrectly classified Test Review [15]\n",
      "Test Review #130: Predicted [Negative] Actual [Positive]\n",
      "Test Review Text: <START> i just saw this movie at the berlin film <UNKNOWN> children's program and it just killed me and pretty much everyone else in the audience and make no mistake about it this film belongs into the all time 250 let me tell you that i'm in no way associated with the creators of this film if that's what you come to believe reading this no but this actually is it <UNKNOWN> the kid's film label on it <UNKNOWN> girl is on almost every account a classic as in biblical the story concerns 12 year old <UNKNOWN> <UNKNOWN> julie who is <UNKNOWN> to learn of her <UNKNOWN> <UNKNOWN> illness special surgery in the us would cost 1 5 million and of course nobody could afford that so <UNKNOWN> and her friends <UNKNOWN> and sebastian do what every good kid would and <UNKNOWN> a bank sounds corny don't forget this is not america and is by no means the tear <UNKNOWN> robin williams <UNKNOWN> <UNKNOWN> du <UNKNOWN> nobody takes seriously anyway director <UNKNOWN> set out to make a big budget action comedy for kids and boy did he succeed let me put it this way this film rocks like no kid film and few others did before and there's a whole lot more to it than just the action after about 20 minutes of by the numbers exposition well granted it into a monster that br br effortlessly puts mission impossible to shame the numerous action sequences are masterfully staged and look real expensive take that mummy br br <UNKNOWN> almost every other movie suspense wise no easy they're only kids antics here br br easily <UNKNOWN> a dense story with enough laughs to make jim carrey look for career <UNKNOWN> br br <UNKNOWN> to both damon <UNKNOWN> and karate kid within the same seconds br br comes up with so much wicked humor that side of p c that i can hear the american ratings board wet their pants from over here br br manages to actually be tender and serious and sexy at the same time what am i saying they're kids they're kids <UNKNOWN> watch that last scene br br stars <UNKNOWN> anderson who since last years is everybody's favourite kid actor br br what a ride\n",
      "\n",
      "Incorrectly classified Test Review [16]\n",
      "Test Review #139: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> some people like to tell you that deep space 9 is the best of all the star trek shows because it <UNKNOWN> character development and continuity and features a more complex background and ongoing plots in some ways this makes it more satisfying but in many ways the show fails entirely br br the series starts out as a soap opera on a space station with two entire seasons of generic science fiction stories balanced with banal subplots about the characters the characters are a good bunch and most of the actors are decent but i think the writers tried too hard to make them normal by normal they actually mean ordinary and tedious br br at the end of season two we are introduced to the <UNKNOWN> who hang around <UNKNOWN> for a while before finally going to war with the good guys in season five this is the main story arc of the show but it only takes up a <UNKNOWN> of the entire series we still get lame stand alone episodes heroes still get stranded on weird planets for forty five minutes and there's an awful lot of low brow comedy featuring the greedy goofy <UNKNOWN> a lot of episodes are merely dull and some are unwatchable br br the <UNKNOWN> main villains are bent on <UNKNOWN> <UNKNOWN> for the convenient reason that well they just don't like anyone the entire war is presented with a naive lack of moral complexity and imagination <UNKNOWN> space battles appear with great <UNKNOWN> from season three <UNKNOWN> but these are carried out in <UNKNOWN> simplistic ways such as two huge of super advanced <UNKNOWN> flying right at each other and <UNKNOWN> away the writers of <UNKNOWN> including the talented ronald d moore later of battlestar galactica fame <UNKNOWN> up their monotonous show by starting a war but at heart it is still a <UNKNOWN> soap br br <UNKNOWN> remains a very frustrating experience the continuous story is too flat and obvious to be really gripping and the characters never truly develop in interesting ways <UNKNOWN> 5 and battlestar galactica both <UNKNOWN> the promise made by <UNKNOWN> and did everything much better for star trek stick with the original and the next generation\n",
      "\n",
      "Incorrectly classified Test Review [17]\n",
      "Test Review #147: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> having enjoyed neil <UNKNOWN> writing especially his collaboration with <UNKNOWN> in the dream hunters in the past i figured <UNKNOWN> to be a sure thing and was very disappointed the beginning live action section of the movie was intriguing enough the relationships between the characters was believable and easy to empathize with and i loved the sets the <UNKNOWN> and <UNKNOWN> artwork the subsequent computer generated scenes however were excruciating the dialogue was awkward and pretentious the interaction between the live actors and the cgi horrifying events occurred for the <UNKNOWN> reasons and most events seemed superfluous to whatever plot may have existed i only watched the first twenty or thirty minutes of the movie so i'm not exactly an authority but i strongly recommend that you don't watch any of it at all and stick with <UNKNOWN> strong written work\n",
      "\n",
      "Incorrectly classified Test Review [18]\n",
      "Test Review #152: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> i can pretend no knowledge of cinematography or mr <UNKNOWN> but i know <UNKNOWN> and i love her people in july my 14 year old son and i traveled to turkey in search of some remains of the neighborhood where his great grandfather lived until the great <UNKNOWN> of <UNKNOWN> in <UNKNOWN> reading the summary of the film <UNKNOWN> from <UNKNOWN> i thought that perhaps i might learn something more about the forced <UNKNOWN> of modern <UNKNOWN> if i did not have a home in <UNKNOWN> had i not been to <UNKNOWN> 28 times in as many years were i not familiar with dozens of islands and cities in <UNKNOWN> and if i had never enjoyed the friendship of these <UNKNOWN> life <UNKNOWN> people i might have believed that this had something to do with modern <UNKNOWN> as a professor at a new jersey state college let me assure you that i am familiar with the history of the period covered in the film indeed my wife's uncle was murdered by the <UNKNOWN> during the communist grab for power my mother in law lived through the italian invasion and german <UNKNOWN> barely these characters on the screen speak greek they listen to greek music but who are they no they are not even vaguely greek of course they are not people at all but simply <UNKNOWN> they are that which the artist <UNKNOWN> when life does not entirely fit or is <UNKNOWN> to his perception of how it was or should have been all represent some aspect of post wwi <UNKNOWN> that greater outside forces <UNKNOWN> to a fate they didn't deserve as we <UNKNOWN> in the late 70's in america the revolution didn't happen for an <UNKNOWN> artist this is no joke it's in fact grounds to put us through two and a half hours of torment and it's all because the various powers <UNKNOWN> of guards in different colored uniforms didn't allow the generation after the <UNKNOWN> of <UNKNOWN> to follow the call of peace and freedom the music of <UNKNOWN> and his fellow musicians i e the movement the cause this dark surreal <UNKNOWN> <UNKNOWN> the true and heroic efforts of the greek people to sustain their lust for life through the <UNKNOWN> of the 20th century to achieve more than any of their <UNKNOWN> neighbors to have become so politically evolved and <UNKNOWN> integrated\n",
      "\n",
      "Incorrectly classified Test Review [19]\n",
      "Test Review #154: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> i saw this movie many years ago and just for kicks decided to rent it and watch it again the plot is a <UNKNOWN> copy from fright night i did like the hairy vampire and the bug eating driver otherwise it was not good at all\n",
      "\n",
      "Incorrectly classified Test Review [20]\n",
      "Test Review #156: Predicted [Positive] Actual [Negative]\n",
      "Test Review Text: <START> i rented this when it came out on video <UNKNOWN> in 1995 after <UNKNOWN> it again my idea about it hasn't changed much br br i was an adult then and i'm still an adult now lol br br the illogical elements mentioned by other reviewers didn't bother me this isn't a documentary it's a fantasy story where animals can talk br br while i didn't care for much of the songs i liked the one at the end of the picture where it's sang by barry <UNKNOWN> and another person br br some people seem to make an excuse for it's primitive animation by saying that cgi wasn't used often in animated features but let's not forget that the lion king was released about a year earlier and that packed possibly more excellence than any animated feature that came before it br br but i think it's pretty fair to say that the <UNKNOWN> and the was made on the cheap while the lion king wasn't br br the high points for me in 1995 as well as today is the suspense generated by the few dangerous mostly underwater chase scenes br br i also liked the opening scene which takes place on a music notes page and a little bit of the love story but most of the time the story dragged on and was boring br br worth a look if you like animation but if you're an adult and not a risk taker go get another walt disney production instead of this\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_classes_reshaped = np.reshape(predicted_classes, 25000)\n",
    "\n",
    "incorrect = np.nonzero(predicted_classes_reshaped!=y_test)[0]\n",
    "\n",
    "# We select the first 10 incorrectly classified reviews\n",
    "for j, incorrect in enumerate(incorrect[0:20]):\n",
    "    \n",
    "    predicted = class_names[predicted_classes_reshaped[incorrect]]\n",
    "    actual = class_names[y_test[incorrect]]\n",
    "    human_readable_review = decode_review(x_test[incorrect])\n",
    "    \n",
    "    print(\"Incorrectly classified Test Review [\"+ str(j+1) +\"]\") \n",
    "    print(\"Test Review #\" + str(incorrect)  + \": Predicted [\"+ predicted + \"] Actual [\"+ actual + \"]\")\n",
    "    print(\"Test Review Text: \" + human_readable_review.replace(\"<PAD> \", \"\"))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlAfxIoTrtYa"
   },
   "source": [
    "## Run your own text against the trained model\n",
    "\n",
    "This is a fun way to test out the limits of the trained model. To avoid getting errors - type in lower case only and do not use punctuation! \n",
    "\n",
    "You'll see the raw prediction from the model - basically a value between 0 and 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "id": "UEKEB0DpD_8P",
    "outputId": "3b9c092a-71a1-42b2-beb3-7e85a97c238a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: this was a terrible film with too much sex and violence i walked out halfway through\n",
      "Raw Prediction: 0.15518728\n",
      "Predicted Class: Negative\n"
     ]
    }
   ],
   "source": [
    "# Write your own review\n",
    "review = \"this was a terrible film with too much sex and violence i walked out halfway through\"\n",
    "#review = \"this is the best film i have ever seen it is great and fantastic and i loved it\"\n",
    "#review = \"this was an awful film that i will never see again\"\n",
    "\n",
    "# Encode review (replace word with integers)\n",
    "tmp = []\n",
    "for word in review.split(\" \"):\n",
    "    tmp.append(word_index[word])\n",
    "\n",
    "# Ensure review is 500 words long (by padding or truncating)\n",
    "tmp_padded = sequence.pad_sequences([tmp], maxlen=review_length) \n",
    "\n",
    "# Run your processed review against the trained model\n",
    "rawprediction = model.predict(array([tmp_padded][0]))[0][0]\n",
    "prediction = int(round(rawprediction))\n",
    "\n",
    "# Test the model and print the result\n",
    "print(\"Review: \" + review)\n",
    "print(\"Raw Prediction: \" + str(rawprediction))\n",
    "print(\"Predicted Class: \" + class_names[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM_IMDB_Sentiment_Example HuyRev.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Internship",
   "language": "python",
   "name": "internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
