{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NM5s0GL_v7W5"
   },
   "source": [
    "**Connect with google drive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQZKZP8QEbvU"
   },
   "source": [
    "**Step_1: Get the data of 20 companies from yahoo web and store in google drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from datetime import date\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13137,
     "status": "ok",
     "timestamp": 1620449592429,
     "user": {
      "displayName": "黎美英",
      "photoUrl": "",
      "userId": "17348745847824899947"
     },
     "user_tz": -480
    },
    "id": "pE7Sw87NBvrZ",
    "outputId": "44090dae-d474-4eba-85b3-419f275d19b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 2021-07-17 19:19:18.878745\n",
      "INTC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AMD\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CSCO\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AAPL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MU\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NVDA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "QCOM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AMZN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NFLX\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "FB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GOOG\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BABA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EBAY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "IBM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "XLNX\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TXN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NOK\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TSLA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MSFT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SNPS\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "#datetime is a Python module\n",
    "\n",
    "\n",
    "# Set the start and end date\n",
    "start_date = '2011-01-01'\n",
    "\n",
    "# Get data to today\n",
    "today = datetime.datetime.today()\n",
    "\n",
    "# Set the list including 20'str' acronym of 20 companies\n",
    "list = ['INTC','AMD', 'CSCO', 'AAPL', 'MU', 'NVDA', 'QCOM', 'AMZN', 'NFLX', 'FB', 'GOOG', 'BABA', 'EBAY', 'IBM', 'XLNX', 'TXN', 'NOK', 'TSLA', 'MSFT', 'SNPS']\n",
    "\n",
    "# Get the data\n",
    "files=[]\n",
    "\n",
    "# Create a data folder in my google drive.\n",
    "def SaveData(df, filename):\n",
    "  df.to_csv('Dataset/'+filename+'.csv')\n",
    "\n",
    "def GetData(acronym):\n",
    "  print (acronym)\n",
    "  data = pdr.get_data_yahoo(acronym, start = start_date, end = today )\n",
    "  dataname= acronym\n",
    "  files.append(dataname)\n",
    "  SaveData(data, dataname)\n",
    "\n",
    "print(\"Today is \" + str(today))\n",
    "#Get data, and save that data as \"str\".csv\n",
    "for i in list:\n",
    "  GetData(i)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guZIhj8hKKD0"
   },
   "source": [
    "### Requirement: \n",
    "30 ngày liên tiếp là input đầu vào của cột Adj => Predict ra cho ngày 31 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>11.533929</td>\n",
       "      <td>11.552857</td>\n",
       "      <td>11.475357</td>\n",
       "      <td>11.520000</td>\n",
       "      <td>9.906079</td>\n",
       "      <td>193508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>11.630000</td>\n",
       "      <td>11.795000</td>\n",
       "      <td>11.601429</td>\n",
       "      <td>11.770357</td>\n",
       "      <td>10.121364</td>\n",
       "      <td>445138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>11.872857</td>\n",
       "      <td>11.875000</td>\n",
       "      <td>11.719643</td>\n",
       "      <td>11.831786</td>\n",
       "      <td>10.174186</td>\n",
       "      <td>309080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>11.769643</td>\n",
       "      <td>11.940714</td>\n",
       "      <td>11.767857</td>\n",
       "      <td>11.928571</td>\n",
       "      <td>10.257413</td>\n",
       "      <td>255519600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>11.954286</td>\n",
       "      <td>11.973214</td>\n",
       "      <td>11.889286</td>\n",
       "      <td>11.918929</td>\n",
       "      <td>10.249121</td>\n",
       "      <td>300428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>146.210007</td>\n",
       "      <td>146.320007</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.500000</td>\n",
       "      <td>144.500000</td>\n",
       "      <td>76299700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>144.029999</td>\n",
       "      <td>147.460007</td>\n",
       "      <td>143.630005</td>\n",
       "      <td>145.639999</td>\n",
       "      <td>145.639999</td>\n",
       "      <td>100698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>148.100006</td>\n",
       "      <td>149.570007</td>\n",
       "      <td>147.679993</td>\n",
       "      <td>149.149994</td>\n",
       "      <td>149.149994</td>\n",
       "      <td>127050800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>149.240005</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>147.089996</td>\n",
       "      <td>148.479996</td>\n",
       "      <td>148.479996</td>\n",
       "      <td>106820300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>148.460007</td>\n",
       "      <td>149.759995</td>\n",
       "      <td>145.880005</td>\n",
       "      <td>146.389999</td>\n",
       "      <td>146.389999</td>\n",
       "      <td>93100300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2653 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     2010-12-31   11.533929   11.552857   11.475357   11.520000    9.906079   \n",
       "1     2011-01-03   11.630000   11.795000   11.601429   11.770357   10.121364   \n",
       "2     2011-01-04   11.872857   11.875000   11.719643   11.831786   10.174186   \n",
       "3     2011-01-05   11.769643   11.940714   11.767857   11.928571   10.257413   \n",
       "4     2011-01-06   11.954286   11.973214   11.889286   11.918929   10.249121   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2648  2021-07-12  146.210007  146.320007  144.000000  144.500000  144.500000   \n",
       "2649  2021-07-13  144.029999  147.460007  143.630005  145.639999  145.639999   \n",
       "2650  2021-07-14  148.100006  149.570007  147.679993  149.149994  149.149994   \n",
       "2651  2021-07-15  149.240005  150.000000  147.089996  148.479996  148.479996   \n",
       "2652  2021-07-16  148.460007  149.759995  145.880005  146.389999  146.389999   \n",
       "\n",
       "         Volume  \n",
       "0     193508000  \n",
       "1     445138400  \n",
       "2     309080800  \n",
       "3     255519600  \n",
       "4     300428800  \n",
       "...         ...  \n",
       "2648   76299700  \n",
       "2649  100698900  \n",
       "2650  127050800  \n",
       "2651  106820300  \n",
       "2652   93100300  \n",
       "\n",
       "[2653 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/AAPL.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         9.906079\n",
       "1        10.121364\n",
       "2        10.174186\n",
       "3        10.257413\n",
       "4        10.249121\n",
       "           ...    \n",
       "2648    144.500000\n",
       "2649    145.639999\n",
       "2650    149.149994\n",
       "2651    148.479996\n",
       "2652    146.389999\n",
       "Name: Adj Close, Length: 2653, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()['Adj Close']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM are sensitive to the scale of the data. so we apply MinMax scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(np.array(df).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00159427]\n",
      " [0.0031379 ]\n",
      " [0.00351664]\n",
      " ...\n",
      " [1.        ]\n",
      " [0.99519598]\n",
      " [0.98021031]]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1857, 796)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting dataset into train and test split\n",
    "training_size = int(len(df)*0.7)\n",
    "test_size = len(df)-training_size\n",
    "train_data, test_data = df[0:training_size, :], df[training_size:len(df), :1]\n",
    "training_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 30\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 30)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 30, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTFi7KBJJril"
   },
   "source": [
    "**Step_2: Working with LSTM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(15, return_sequences=True,input_shape=(30,1)))\n",
    "model.add(LSTM(15, return_sequences=True))\n",
    "model.add(LSTM(15))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 30, 15)            1020      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30, 15)            1860      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 15)                1860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 4,756\n",
      "Trainable params: 4,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "29/29 [==============================] - 5s 53ms/step - loss: 0.0032 - val_loss: 0.0691\n",
      "Epoch 2/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2.0299e-04 - val_loss: 0.0337\n",
      "Epoch 3/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 8.5268e-05 - val_loss: 0.0297\n",
      "Epoch 4/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.7707e-05 - val_loss: 0.0301\n",
      "Epoch 5/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.6070e-05 - val_loss: 0.0309\n",
      "Epoch 6/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.7336e-05 - val_loss: 0.0295e\n",
      "Epoch 7/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9608e-05 - val_loss: 0.0302\n",
      "Epoch 8/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6434e-05 - val_loss: 0.0320\n",
      "Epoch 9/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 7.3878e-05 - val_loss: 0.0292\n",
      "Epoch 10/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5900e-05 - val_loss: 0.0287\n",
      "Epoch 11/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2624e-05 - val_loss: 0.0275\n",
      "Epoch 12/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.5028e-05 - val_loss: 0.0260\n",
      "Epoch 13/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3191e-05 - val_loss: 0.0264\n",
      "Epoch 14/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.1214e-05 - val_loss: 0.0270\n",
      "Epoch 15/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.0265e-05 - val_loss: 0.0241\n",
      "Epoch 16/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.1191e-05 - val_loss: 0.0246\n",
      "Epoch 17/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 6.8608e-05 - val_loss: 0.0258\n",
      "Epoch 18/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 6.9042e-05 - val_loss: 0.0233\n",
      "Epoch 19/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 6.7156e-05 - val_loss: 0.0242\n",
      "Epoch 20/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 6.8801e-05 - val_loss: 0.0218\n",
      "Epoch 21/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 6.9250e-05 - val_loss: 0.0232\n",
      "Epoch 22/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 6.4338e-05 - val_loss: 0.0237\n",
      "Epoch 23/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 6.7937e-05 - val_loss: 0.0203\n",
      "Epoch 24/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 6.6293e-05 - val_loss: 0.0190\n",
      "Epoch 25/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 6.1413e-05 - val_loss: 0.0205\n",
      "Epoch 26/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 6.1815e-05 - val_loss: 0.0197\n",
      "Epoch 27/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 6.0303e-05 - val_loss: 0.0190\n",
      "Epoch 28/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.8023e-05 - val_loss: 0.0190\n",
      "Epoch 29/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 6.2756e-05 - val_loss: 0.0174\n",
      "Epoch 30/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.8960e-05 - val_loss: 0.0161\n",
      "Epoch 31/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 5.6060e-05 - val_loss: 0.0175\n",
      "Epoch 32/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 5.7352e-05 - val_loss: 0.0157\n",
      "Epoch 33/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.4696e-05 - val_loss: 0.0144\n",
      "Epoch 34/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.5111e-05 - val_loss: 0.0155\n",
      "Epoch 35/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 5.2299e-05 - val_loss: 0.0134\n",
      "Epoch 36/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.2327e-05 - val_loss: 0.0140\n",
      "Epoch 37/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.4348e-05 - val_loss: 0.0108\n",
      "Epoch 38/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 5.3641e-05 - val_loss: 0.0152\n",
      "Epoch 39/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.1479e-05 - val_loss: 0.0130\n",
      "Epoch 40/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.9296e-05 - val_loss: 0.0126\n",
      "Epoch 41/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 4.8580e-05 - val_loss: 0.0096\n",
      "Epoch 42/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 4.8495e-05 - val_loss: 0.0106\n",
      "Epoch 43/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 5.1345e-05 - val_loss: 0.0101\n",
      "Epoch 44/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.0519e-05 - val_loss: 0.0112\n",
      "Epoch 45/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.8952e-05 - val_loss: 0.0089\n",
      "Epoch 46/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 4.5967e-05 - val_loss: 0.0099\n",
      "Epoch 47/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.4142e-05 - val_loss: 0.0083\n",
      "Epoch 48/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 4.7050e-05 - val_loss: 0.0086\n",
      "Epoch 49/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 5.0146e-05 - val_loss: 0.0068\n",
      "Epoch 50/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.4276e-05 - val_loss: 0.0086\n",
      "Epoch 51/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 4.6267e-05 - val_loss: 0.0070\n",
      "Epoch 52/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 4.8917e-05 - val_loss: 0.0068\n",
      "Epoch 53/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.4151e-05 - val_loss: 0.0072\n",
      "Epoch 54/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 4.5398e-05 - val_loss: 0.0064\n",
      "Epoch 55/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 4.3924e-05 - val_loss: 0.0062\n",
      "Epoch 56/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 4.2438e-05 - val_loss: 0.0055\n",
      "Epoch 57/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.8551e-05 - val_loss: 0.0068\n",
      "Epoch 58/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 4.2973e-05 - val_loss: 0.0076\n",
      "Epoch 59/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.1832e-05 - val_loss: 0.0072\n",
      "Epoch 60/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 4.4153e-05 - val_loss: 0.0066\n",
      "Epoch 61/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 4.0462e-05 - val_loss: 0.0074\n",
      "Epoch 62/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 4.0024e-05 - val_loss: 0.0064\n",
      "Epoch 63/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.0362e-05 - val_loss: 0.0079\n",
      "Epoch 64/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 3.8542e-05 - val_loss: 0.0070\n",
      "Epoch 65/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 3.9292e-05 - val_loss: 0.0077\n",
      "Epoch 66/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 3.7677e-05 - val_loss: 0.0069\n",
      "Epoch 67/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 3.5741e-05 - val_loss: 0.0058\n",
      "Epoch 68/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 3.6346e-05 - val_loss: 0.0041\n",
      "Epoch 69/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.0792e-05 - val_loss: 0.0064\n",
      "Epoch 70/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.4493e-05 - val_loss: 0.0062\n",
      "Epoch 71/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.7220e-05 - val_loss: 0.0054\n",
      "Epoch 72/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 3.5275e-05 - val_loss: 0.0067\n",
      "Epoch 73/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.6391e-05 - val_loss: 0.0072\n",
      "Epoch 74/500\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 3.4230e-05 - val_loss: 0.0065\n",
      "Epoch 75/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.3757e-05 - val_loss: 0.0079\n",
      "Epoch 76/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.3839e-05 - val_loss: 0.0059\n",
      "Epoch 77/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.2665e-05 - val_loss: 0.0065\n",
      "Epoch 78/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.1774e-05 - val_loss: 0.0072\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 26ms/step - loss: 3.3298e-05 - val_loss: 0.0084\n",
      "Epoch 80/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.4971e-05 - val_loss: 0.0064\n",
      "Epoch 81/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.2093e-05 - val_loss: 0.0059\n",
      "Epoch 82/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.1669e-05 - val_loss: 0.0073\n",
      "Epoch 83/500\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 3.4076e-05 - val_loss: 0.0077\n",
      "Epoch 84/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 3.1060e-05 - val_loss: 0.0063\n",
      "Epoch 85/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.0053e-05 - val_loss: 0.0075\n",
      "Epoch 86/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.0781e-05 - val_loss: 0.0071\n",
      "Epoch 87/500\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 2.9990e-05 - val_loss: 0.0063\n",
      "Epoch 88/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 2.9089e-05 - val_loss: 0.0075\n",
      "Epoch 89/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 2.8752e-05 - val_loss: 0.0074\n",
      "Epoch 90/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.0895e-05 - val_loss: 0.0069\n",
      "Epoch 91/500\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 3.0874e-05 - val_loss: 0.0070\n",
      "Epoch 92/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.2794e-05 - val_loss: 0.0070\n",
      "Epoch 93/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.0295e-05 - val_loss: 0.0098\n",
      "Epoch 94/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.2199e-05 - val_loss: 0.0074\n",
      "Epoch 95/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 2.7406e-05 - val_loss: 0.0068\n",
      "Epoch 96/500\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 2.6795e-05 - val_loss: 0.0065\n",
      "Epoch 97/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 2.6514e-05 - val_loss: 0.0081\n",
      "Epoch 98/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 2.8130e-05 - val_loss: 0.0089\n",
      "Epoch 99/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 2.8247e-05 - val_loss: 0.0069\n",
      "Epoch 100/500\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 2.6320e-05 - val_loss: 0.0073\n",
      "Epoch 101/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 2.5631e-05 - val_loss: 0.0066\n",
      "Epoch 102/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 2.4850e-05 - val_loss: 0.0072\n",
      "Epoch 103/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2.5454e-05 - val_loss: 0.0071\n",
      "Epoch 104/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2.9745e-05 - val_loss: 0.0062\n",
      "Epoch 105/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2.9323e-05 - val_loss: 0.0056\n",
      "Epoch 106/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 3.1738e-05 - val_loss: 0.0071\n",
      "Epoch 107/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2.6226e-05 - val_loss: 0.0065\n",
      "Epoch 108/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2.3269e-05 - val_loss: 0.0063\n",
      "Epoch 109/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2.4704e-05 - val_loss: 0.0047\n",
      "Epoch 110/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2.6869e-05 - val_loss: 0.0071\n",
      "Epoch 111/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2.4668e-05 - val_loss: 0.0063\n",
      "Epoch 112/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2.6152e-05 - val_loss: 0.0060\n",
      "Epoch 113/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2.2262e-05 - val_loss: 0.0054\n",
      "Epoch 114/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2.3103e-05 - val_loss: 0.0066\n",
      "Epoch 115/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2.1146e-05 - val_loss: 0.0058\n",
      "Epoch 116/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2.1170e-05 - val_loss: 0.0049\n",
      "Epoch 117/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2.1919e-05 - val_loss: 0.0058\n",
      "Epoch 118/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2.0023e-05 - val_loss: 0.0063\n",
      "Epoch 119/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2.1609e-05 - val_loss: 0.0055\n",
      "Epoch 120/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2.0664e-05 - val_loss: 0.0057\n",
      "Epoch 121/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.9257e-05 - val_loss: 0.0063\n",
      "Epoch 122/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2.0681e-05 - val_loss: 0.0056\n",
      "Epoch 123/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.8868e-05 - val_loss: 0.0059\n",
      "Epoch 124/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.7944e-05 - val_loss: 0.0063\n",
      "Epoch 125/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.8306e-05 - val_loss: 0.0066\n",
      "Epoch 126/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.7664e-05 - val_loss: 0.0064\n",
      "Epoch 127/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.7925e-05 - val_loss: 0.0061\n",
      "Epoch 128/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.7357e-05 - val_loss: 0.0057\n",
      "Epoch 129/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.9332e-05 - val_loss: 0.0045\n",
      "Epoch 130/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.7114e-05 - val_loss: 0.0061\n",
      "Epoch 131/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.7447e-05 - val_loss: 0.0046\n",
      "Epoch 132/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.7757e-05 - val_loss: 0.0043\n",
      "Epoch 133/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.7480e-05 - val_loss: 0.0051\n",
      "Epoch 134/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.9074e-05 - val_loss: 0.0032\n",
      "Epoch 135/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.7755e-05 - val_loss: 0.0044\n",
      "Epoch 136/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.6835e-05 - val_loss: 0.0048\n",
      "Epoch 137/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.6282e-05 - val_loss: 0.0044\n",
      "Epoch 138/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.9662e-05 - val_loss: 0.0042\n",
      "Epoch 139/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 1.6047e-05 - val_loss: 0.0043\n",
      "Epoch 140/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.6231e-05 - val_loss: 0.0041\n",
      "Epoch 141/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.8008e-05 - val_loss: 0.0048\n",
      "Epoch 142/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.6312e-05 - val_loss: 0.0037\n",
      "Epoch 143/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.5733e-05 - val_loss: 0.0042\n",
      "Epoch 144/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.5053e-05 - val_loss: 0.0041\n",
      "Epoch 145/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.4267e-05 - val_loss: 0.0043\n",
      "Epoch 146/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.4080e-05 - val_loss: 0.0048\n",
      "Epoch 147/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.5003e-05 - val_loss: 0.0041\n",
      "Epoch 148/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.5244e-05 - val_loss: 0.0038\n",
      "Epoch 149/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.6377e-05 - val_loss: 0.0034\n",
      "Epoch 150/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.5817e-05 - val_loss: 0.0037\n",
      "Epoch 151/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.3797e-05 - val_loss: 0.0043\n",
      "Epoch 152/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.3616e-05 - val_loss: 0.0037\n",
      "Epoch 153/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.4430e-05 - val_loss: 0.0039\n",
      "Epoch 154/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.3684e-05 - val_loss: 0.0038\n",
      "Epoch 155/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.3702e-05 - val_loss: 0.0034\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 22ms/step - loss: 1.3669e-05 - val_loss: 0.0026\n",
      "Epoch 157/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.3680e-05 - val_loss: 0.0033\n",
      "Epoch 158/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.4410e-05 - val_loss: 0.0033\n",
      "Epoch 159/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.9832e-05 - val_loss: 0.0042\n",
      "Epoch 160/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.3045e-05 - val_loss: 0.0033\n",
      "Epoch 161/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2885e-05 - val_loss: 0.0039\n",
      "Epoch 162/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.2756e-05 - val_loss: 0.0040\n",
      "Epoch 163/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.4439e-05 - val_loss: 0.0035\n",
      "Epoch 164/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2189e-05 - val_loss: 0.0036\n",
      "Epoch 165/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.3878e-05 - val_loss: 0.0041\n",
      "Epoch 166/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2831e-05 - val_loss: 0.0037\n",
      "Epoch 167/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2886e-05 - val_loss: 0.0029\n",
      "Epoch 168/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2636e-05 - val_loss: 0.0039\n",
      "Epoch 169/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2031e-05 - val_loss: 0.0036\n",
      "Epoch 170/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.4125e-05 - val_loss: 0.0029\n",
      "Epoch 171/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.2780e-05 - val_loss: 0.0029\n",
      "Epoch 172/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.4003e-05 - val_loss: 0.0035\n",
      "Epoch 173/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1738e-05 - val_loss: 0.0033\n",
      "Epoch 174/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1760e-05 - val_loss: 0.0032\n",
      "Epoch 175/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1316e-05 - val_loss: 0.0032\n",
      "Epoch 176/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2124e-05 - val_loss: 0.0032\n",
      "Epoch 177/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1515e-05 - val_loss: 0.0030\n",
      "Epoch 178/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1776e-05 - val_loss: 0.0026\n",
      "Epoch 179/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1614e-05 - val_loss: 0.0033\n",
      "Epoch 180/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1784e-05 - val_loss: 0.0033\n",
      "Epoch 181/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2124e-05 - val_loss: 0.0033\n",
      "Epoch 182/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0750e-05 - val_loss: 0.0029\n",
      "Epoch 183/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0843e-05 - val_loss: 0.0030\n",
      "Epoch 184/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.2102e-05 - val_loss: 0.0021\n",
      "Epoch 185/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2339e-05 - val_loss: 0.0024\n",
      "Epoch 186/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2624e-05 - val_loss: 0.0036\n",
      "Epoch 187/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1806e-05 - val_loss: 0.0034\n",
      "Epoch 188/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2681e-05 - val_loss: 0.0032\n",
      "Epoch 189/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0523e-05 - val_loss: 0.0038\n",
      "Epoch 190/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2887e-05 - val_loss: 0.0030\n",
      "Epoch 191/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.0501e-05 - val_loss: 0.0029\n",
      "Epoch 192/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0914e-05 - val_loss: 0.0029\n",
      "Epoch 193/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.8889e-06 - val_loss: 0.0031\n",
      "Epoch 194/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0852e-05 - val_loss: 0.0022\n",
      "Epoch 195/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0342e-05 - val_loss: 0.0033\n",
      "Epoch 196/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.8832e-06 - val_loss: 0.0028\n",
      "Epoch 197/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.2664e-05 - val_loss: 0.0029\n",
      "Epoch 198/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0292e-05 - val_loss: 0.0028\n",
      "Epoch 199/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0061e-05 - val_loss: 0.0028\n",
      "Epoch 200/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.8214e-06 - val_loss: 0.0028\n",
      "Epoch 201/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.1354e-05 - val_loss: 0.0029\n",
      "Epoch 202/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.3137e-05 - val_loss: 0.0029\n",
      "Epoch 203/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.8841e-06 - val_loss: 0.0032\n",
      "Epoch 204/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.5539e-06 - val_loss: 0.0034\n",
      "Epoch 205/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.5652e-06 - val_loss: 0.0026\n",
      "Epoch 206/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0752e-05 - val_loss: 0.0036\n",
      "Epoch 207/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 1.1353e-05 - val_loss: 0.0040\n",
      "Epoch 208/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0964e-05 - val_loss: 0.0032\n",
      "Epoch 209/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.2342e-06 - val_loss: 0.0029\n",
      "Epoch 210/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 9.7087e-06 - val_loss: 0.0029\n",
      "Epoch 211/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 9.8333e-06 - val_loss: 0.0031\n",
      "Epoch 212/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.0141e-05 - val_loss: 0.0031\n",
      "Epoch 213/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 9.7442e-06 - val_loss: 0.0028\n",
      "Epoch 214/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.0435e-05 - val_loss: 0.0029\n",
      "Epoch 215/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.8896e-06 - val_loss: 0.0029\n",
      "Epoch 216/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.2810e-06 - val_loss: 0.0024\n",
      "Epoch 217/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.8152e-06 - val_loss: 0.0025\n",
      "Epoch 218/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 9.1302e-06 - val_loss: 0.0032\n",
      "Epoch 219/500\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1.1156e-05 - val_loss: 0.0034\n",
      "Epoch 220/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 9.3972e-06 - val_loss: 0.0030\n",
      "Epoch 221/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.7377e-06 - val_loss: 0.0026\n",
      "Epoch 222/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.4310e-06 - val_loss: 0.0029\n",
      "Epoch 223/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 9.0156e-06 - val_loss: 0.0026\n",
      "Epoch 224/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 9.2790e-06 - val_loss: 0.0030\n",
      "Epoch 225/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.0694e-05 - val_loss: 0.0031\n",
      "Epoch 226/500\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 8.4635e-06 - val_loss: 0.0034\n",
      "Epoch 227/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.6554e-06 - val_loss: 0.0028\n",
      "Epoch 228/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.2837e-06 - val_loss: 0.0032\n",
      "Epoch 229/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.3902e-05 - val_loss: 0.0032\n",
      "Epoch 230/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.6087e-06 - val_loss: 0.0030\n",
      "Epoch 231/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 9.5658e-06 - val_loss: 0.0025\n",
      "Epoch 232/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.3530e-06 - val_loss: 0.0026\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 23ms/step - loss: 9.1801e-06 - val_loss: 0.0031\n",
      "Epoch 234/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8.2558e-06 - val_loss: 0.0031\n",
      "Epoch 235/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.7399e-06 - val_loss: 0.0030\n",
      "Epoch 236/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.1466e-06 - val_loss: 0.0022\n",
      "Epoch 237/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.0731e-06 - val_loss: 0.0030\n",
      "Epoch 238/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8.4868e-06 - val_loss: 0.0028\n",
      "Epoch 239/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.0642e-06 - val_loss: 0.0028\n",
      "Epoch 240/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.5684e-06 - val_loss: 0.0028\n",
      "Epoch 241/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.9000e-06 - val_loss: 0.0027\n",
      "Epoch 242/500\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 8.0285e-06 - val_loss: 0.0027\n",
      "Epoch 243/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.4097e-06 - val_loss: 0.0030\n",
      "Epoch 244/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8266e-06 - val_loss: 0.0026\n",
      "Epoch 245/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.8346e-06 - val_loss: 0.0026\n",
      "Epoch 246/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2671e-06 - val_loss: 0.0025\n",
      "Epoch 247/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 1.0325e-05 - val_loss: 0.0029\n",
      "Epoch 248/500\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1.1607e-05 - val_loss: 0.0022\n",
      "Epoch 249/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 9.8650e-06 - val_loss: 0.0026\n",
      "Epoch 250/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8.6777e-06 - val_loss: 0.0026\n",
      "Epoch 251/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.0591e-06 - val_loss: 0.0033\n",
      "Epoch 252/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.6537e-06 - val_loss: 0.0030\n",
      "Epoch 253/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.7203e-06 - val_loss: 0.0025\n",
      "Epoch 254/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.5292e-06 - val_loss: 0.0022\n",
      "Epoch 255/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.1605e-06 - val_loss: 0.0029\n",
      "Epoch 256/500\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 8.1371e-06 - val_loss: 0.0028\n",
      "Epoch 257/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.6351e-06 - val_loss: 0.0028\n",
      "Epoch 258/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.5644e-06 - val_loss: 0.0025\n",
      "Epoch 259/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.8965e-06 - val_loss: 0.0026\n",
      "Epoch 260/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.8845e-06 - val_loss: 0.0029\n",
      "Epoch 261/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.6942e-06 - val_loss: 0.0028e-0\n",
      "Epoch 262/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.8698e-06 - val_loss: 0.0027\n",
      "Epoch 263/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.1515e-06 - val_loss: 0.0027\n",
      "Epoch 264/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.9556e-06 - val_loss: 0.0028\n",
      "Epoch 265/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.7449e-06 - val_loss: 0.0025\n",
      "Epoch 266/500\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 8.3804e-06 - val_loss: 0.0032\n",
      "Epoch 267/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.0425e-06 - val_loss: 0.0031\n",
      "Epoch 268/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2037e-06 - val_loss: 0.0025\n",
      "Epoch 269/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.3243e-06 - val_loss: 0.0026\n",
      "Epoch 270/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.6933e-06 - val_loss: 0.0026\n",
      "Epoch 271/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.6594e-06 - val_loss: 0.0028\n",
      "Epoch 272/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2285e-06 - val_loss: 0.0026\n",
      "Epoch 273/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.7497e-06 - val_loss: 0.0024\n",
      "Epoch 274/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.1609e-06 - val_loss: 0.0027\n",
      "Epoch 275/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.4877e-06 - val_loss: 0.0028\n",
      "Epoch 276/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.7390e-06 - val_loss: 0.0027\n",
      "Epoch 277/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.5990e-06 - val_loss: 0.0022\n",
      "Epoch 278/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6367e-06 - val_loss: 0.0025\n",
      "Epoch 279/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.3056e-06 - val_loss: 0.0028\n",
      "Epoch 280/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.2337e-06 - val_loss: 0.0028\n",
      "Epoch 281/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2777e-06 - val_loss: 0.0026\n",
      "Epoch 282/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8029e-06 - val_loss: 0.0027\n",
      "Epoch 283/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4268e-06 - val_loss: 0.0029e-0\n",
      "Epoch 284/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.9325e-06 - val_loss: 0.0029\n",
      "Epoch 285/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.1470e-06 - val_loss: 0.0032\n",
      "Epoch 286/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.4403e-06 - val_loss: 0.0026\n",
      "Epoch 287/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.1838e-06 - val_loss: 0.0027\n",
      "Epoch 288/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2339e-06 - val_loss: 0.0031\n",
      "Epoch 289/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.5884e-06 - val_loss: 0.0031\n",
      "Epoch 290/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6615e-06 - val_loss: 0.0028\n",
      "Epoch 291/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8672e-06 - val_loss: 0.0027\n",
      "Epoch 292/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.3979e-06 - val_loss: 0.0023\n",
      "Epoch 293/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.3081e-06 - val_loss: 0.0025\n",
      "Epoch 294/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.2753e-06 - val_loss: 0.0027\n",
      "Epoch 295/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9480e-06 - val_loss: 0.0034\n",
      "Epoch 296/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.8918e-06 - val_loss: 0.0034\n",
      "Epoch 297/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.8385e-06 - val_loss: 0.0038\n",
      "Epoch 298/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6783e-06 - val_loss: 0.0027\n",
      "Epoch 299/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.1536e-06 - val_loss: 0.0026\n",
      "Epoch 300/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5403e-06 - val_loss: 0.0024\n",
      "Epoch 301/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.9165e-06 - val_loss: 0.0029\n",
      "Epoch 302/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.5777e-06 - val_loss: 0.0026\n",
      "Epoch 303/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5340e-06 - val_loss: 0.0030\n",
      "Epoch 304/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.8975e-06 - val_loss: 0.0026\n",
      "Epoch 305/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.3085e-06 - val_loss: 0.0024\n",
      "Epoch 306/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.7587e-06 - val_loss: 0.0024\n",
      "Epoch 307/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.4795e-06 - val_loss: 0.0028\n",
      "Epoch 308/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.0981e-06 - val_loss: 0.0026e-0\n",
      "Epoch 309/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.4503e-06 - val_loss: 0.0026\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 23ms/step - loss: 8.4913e-06 - val_loss: 0.0025\n",
      "Epoch 311/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.3716e-06 - val_loss: 0.0034\n",
      "Epoch 312/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.3555e-06 - val_loss: 0.0026\n",
      "Epoch 313/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.4052e-06 - val_loss: 0.0023\n",
      "Epoch 314/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.6391e-06 - val_loss: 0.0024\n",
      "Epoch 315/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.2028e-06 - val_loss: 0.0029\n",
      "Epoch 316/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.1540e-06 - val_loss: 0.0029\n",
      "Epoch 317/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.0495e-06 - val_loss: 0.0029\n",
      "Epoch 318/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.5331e-06 - val_loss: 0.0028\n",
      "Epoch 319/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4341e-06 - val_loss: 0.0029\n",
      "Epoch 320/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4622e-06 - val_loss: 0.0026\n",
      "Epoch 321/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.3002e-06 - val_loss: 0.0024\n",
      "Epoch 322/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.0312e-06 - val_loss: 0.0023\n",
      "Epoch 323/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.0425e-06 - val_loss: 0.0029\n",
      "Epoch 324/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9811e-06 - val_loss: 0.0028\n",
      "Epoch 325/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2622e-06 - val_loss: 0.0027\n",
      "Epoch 326/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1.0168e-05 - val_loss: 0.0029\n",
      "Epoch 327/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9797e-06 - val_loss: 0.0026\n",
      "Epoch 328/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.2092e-06 - val_loss: 0.0024\n",
      "Epoch 329/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4179e-06 - val_loss: 0.0024e-0\n",
      "Epoch 330/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4718e-06 - val_loss: 0.0022\n",
      "Epoch 331/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8149e-06 - val_loss: 0.0027\n",
      "Epoch 332/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4687e-06 - val_loss: 0.0023\n",
      "Epoch 333/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.1695e-06 - val_loss: 0.0029\n",
      "Epoch 334/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.3758e-06 - val_loss: 0.0031\n",
      "Epoch 335/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.3776e-06 - val_loss: 0.0026\n",
      "Epoch 336/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5737e-06 - val_loss: 0.0025\n",
      "Epoch 337/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5829e-06 - val_loss: 0.0028\n",
      "Epoch 338/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.0355e-06 - val_loss: 0.0027\n",
      "Epoch 339/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.1594e-06 - val_loss: 0.0028\n",
      "Epoch 340/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.1813e-06 - val_loss: 0.0027\n",
      "Epoch 341/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2473e-06 - val_loss: 0.0025\n",
      "Epoch 342/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.3227e-06 - val_loss: 0.0028\n",
      "Epoch 343/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.8566e-06 - val_loss: 0.0029\n",
      "Epoch 344/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.8089e-06 - val_loss: 0.0033\n",
      "Epoch 345/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4161e-06 - val_loss: 0.0025\n",
      "Epoch 346/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.7059e-06 - val_loss: 0.0024\n",
      "Epoch 347/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9279e-06 - val_loss: 0.0029\n",
      "Epoch 348/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.2819e-06 - val_loss: 0.0031\n",
      "Epoch 349/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2257e-06 - val_loss: 0.0024\n",
      "Epoch 350/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.5652e-06 - val_loss: 0.0026\n",
      "Epoch 351/500\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 8.6153e-06 - val_loss: 0.0028\n",
      "Epoch 352/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.3172e-06 - val_loss: 0.0027\n",
      "Epoch 353/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2763e-06 - val_loss: 0.0024\n",
      "Epoch 354/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.2238e-06 - val_loss: 0.0024\n",
      "Epoch 355/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8.1250e-06 - val_loss: 0.0029\n",
      "Epoch 356/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3806e-06 - val_loss: 0.0026\n",
      "Epoch 357/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.9945e-06 - val_loss: 0.0022\n",
      "Epoch 358/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.0442e-06 - val_loss: 0.0025\n",
      "Epoch 359/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8405e-06 - val_loss: 0.0025\n",
      "Epoch 360/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.7412e-06 - val_loss: 0.0024\n",
      "Epoch 361/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2099e-06 - val_loss: 0.0025\n",
      "Epoch 362/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4428e-06 - val_loss: 0.0026\n",
      "Epoch 363/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5561e-06 - val_loss: 0.0021\n",
      "Epoch 364/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3613e-06 - val_loss: 0.0025\n",
      "Epoch 365/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.3251e-06 - val_loss: 0.0023\n",
      "Epoch 366/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.5682e-06 - val_loss: 0.0028\n",
      "Epoch 367/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.4435e-06 - val_loss: 0.0026\n",
      "Epoch 368/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.5112e-06 - val_loss: 0.0023\n",
      "Epoch 369/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6441e-06 - val_loss: 0.0026\n",
      "Epoch 370/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.3967e-06 - val_loss: 0.0024\n",
      "Epoch 371/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9292e-06 - val_loss: 0.0025\n",
      "Epoch 372/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5994e-06 - val_loss: 0.0030\n",
      "Epoch 373/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8004e-06 - val_loss: 0.0026\n",
      "Epoch 374/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5405e-06 - val_loss: 0.0020\n",
      "Epoch 375/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.5179e-06 - val_loss: 0.0025\n",
      "Epoch 376/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2382e-06 - val_loss: 0.0029\n",
      "Epoch 377/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4400e-06 - val_loss: 0.0023\n",
      "Epoch 378/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.0631e-06 - val_loss: 0.0023\n",
      "Epoch 379/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.6413e-06 - val_loss: 0.0020\n",
      "Epoch 380/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.7938e-06 - val_loss: 0.0027\n",
      "Epoch 381/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2666e-06 - val_loss: 0.0026\n",
      "Epoch 382/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.3502e-06 - val_loss: 0.0025\n",
      "Epoch 383/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.5679e-06 - val_loss: 0.0025\n",
      "Epoch 384/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5441e-06 - val_loss: 0.0025\n",
      "Epoch 385/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 8.0775e-06 - val_loss: 0.0026\n",
      "Epoch 386/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8.1662e-06 - val_loss: 0.0024\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 24ms/step - loss: 7.1891e-06 - val_loss: 0.0028\n",
      "Epoch 388/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.0958e-06 - val_loss: 0.0025\n",
      "Epoch 389/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.2903e-06 - val_loss: 0.0024\n",
      "Epoch 390/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3363e-06 - val_loss: 0.0024\n",
      "Epoch 391/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.4637e-06 - val_loss: 0.0026\n",
      "Epoch 392/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.4090e-06 - val_loss: 0.0023\n",
      "Epoch 393/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.7650e-06 - val_loss: 0.0023\n",
      "Epoch 394/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.8332e-06 - val_loss: 0.0028\n",
      "Epoch 395/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.8066e-06 - val_loss: 0.0024\n",
      "Epoch 396/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.0266e-06 - val_loss: 0.0025\n",
      "Epoch 397/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.1083e-06 - val_loss: 0.0025\n",
      "Epoch 398/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.5759e-06 - val_loss: 0.0026\n",
      "Epoch 399/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8032e-06 - val_loss: 0.0020\n",
      "Epoch 400/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2517e-06 - val_loss: 0.0024\n",
      "Epoch 401/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.3003e-06 - val_loss: 0.0026\n",
      "Epoch 402/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1.0885e-05 - val_loss: 0.0026\n",
      "Epoch 403/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8.2256e-06 - val_loss: 0.0023\n",
      "Epoch 404/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.2326e-06 - val_loss: 0.0024\n",
      "Epoch 405/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.5387e-06 - val_loss: 0.0028\n",
      "Epoch 406/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.9342e-06 - val_loss: 0.0027\n",
      "Epoch 407/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.2263e-06 - val_loss: 0.0028\n",
      "Epoch 408/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.8458e-06 - val_loss: 0.0025\n",
      "Epoch 409/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.5320e-06 - val_loss: 0.0021\n",
      "Epoch 410/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.2739e-06 - val_loss: 0.0026\n",
      "Epoch 411/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2358e-06 - val_loss: 0.0023e-\n",
      "Epoch 412/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.8334e-06 - val_loss: 0.0022\n",
      "Epoch 413/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3187e-06 - val_loss: 0.0025\n",
      "Epoch 414/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9982e-06 - val_loss: 0.0026\n",
      "Epoch 415/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8114e-06 - val_loss: 0.0027\n",
      "Epoch 416/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.0386e-06 - val_loss: 0.0030\n",
      "Epoch 417/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.7364e-06 - val_loss: 0.0021\n",
      "Epoch 418/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.7478e-06 - val_loss: 0.0024\n",
      "Epoch 419/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.7467e-06 - val_loss: 0.0027\n",
      "Epoch 420/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.1625e-06 - val_loss: 0.0026\n",
      "Epoch 421/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.0916e-06 - val_loss: 0.0025\n",
      "Epoch 422/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2441e-06 - val_loss: 0.0022\n",
      "Epoch 423/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8847e-06 - val_loss: 0.0022\n",
      "Epoch 424/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3341e-06 - val_loss: 0.0027\n",
      "Epoch 425/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.4138e-06 - val_loss: 0.0025\n",
      "Epoch 426/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3299e-06 - val_loss: 0.0024\n",
      "Epoch 427/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3100e-06 - val_loss: 0.0025\n",
      "Epoch 428/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 6.9590e-06 - val_loss: 0.0029\n",
      "Epoch 429/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.4475e-06 - val_loss: 0.0029\n",
      "Epoch 430/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.6963e-06 - val_loss: 0.0025\n",
      "Epoch 431/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.6765e-06 - val_loss: 0.0027\n",
      "Epoch 432/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5597e-06 - val_loss: 0.0026\n",
      "Epoch 433/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.0197e-06 - val_loss: 0.0022\n",
      "Epoch 434/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.7028e-06 - val_loss: 0.0024\n",
      "Epoch 435/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2245e-06 - val_loss: 0.0022\n",
      "Epoch 436/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1.0704e-05 - val_loss: 0.0026\n",
      "Epoch 437/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.8428e-06 - val_loss: 0.0030\n",
      "Epoch 438/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.2622e-06 - val_loss: 0.0026\n",
      "Epoch 439/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.1897e-06 - val_loss: 0.0023\n",
      "Epoch 440/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2059e-06 - val_loss: 0.0025\n",
      "Epoch 441/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4495e-06 - val_loss: 0.0023\n",
      "Epoch 442/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.6406e-06 - val_loss: 0.0025\n",
      "Epoch 443/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.3530e-06 - val_loss: 0.0023\n",
      "Epoch 444/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 6.9905e-06 - val_loss: 0.0024\n",
      "Epoch 445/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.1963e-06 - val_loss: 0.0026\n",
      "Epoch 446/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6044e-06 - val_loss: 0.0026\n",
      "Epoch 447/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4692e-06 - val_loss: 0.0023\n",
      "Epoch 448/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.0592e-06 - val_loss: 0.0025\n",
      "Epoch 449/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.0156e-06 - val_loss: 0.0023\n",
      "Epoch 450/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.1635e-06 - val_loss: 0.0022\n",
      "Epoch 451/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.4154e-06 - val_loss: 0.0025\n",
      "Epoch 452/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4992e-06 - val_loss: 0.0024\n",
      "Epoch 453/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.6341e-06 - val_loss: 0.0022\n",
      "Epoch 454/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.6636e-06 - val_loss: 0.0023\n",
      "Epoch 455/500\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 7.2512e-06 - val_loss: 0.0022\n",
      "Epoch 456/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.0361e-06 - val_loss: 0.0023\n",
      "Epoch 457/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6768e-06 - val_loss: 0.0022\n",
      "Epoch 458/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.9849e-06 - val_loss: 0.0023\n",
      "Epoch 459/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.5253e-06 - val_loss: 0.0022\n",
      "Epoch 460/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8298e-06 - val_loss: 0.0019\n",
      "Epoch 461/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.9485e-06 - val_loss: 0.0020\n",
      "Epoch 462/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6575e-06 - val_loss: 0.0023\n",
      "Epoch 463/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.1523e-06 - val_loss: 0.0023\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 21ms/step - loss: 7.0112e-06 - val_loss: 0.0025\n",
      "Epoch 465/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.1739e-06 - val_loss: 0.0030\n",
      "Epoch 466/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8.0688e-06 - val_loss: 0.0027\n",
      "Epoch 467/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.4083e-06 - val_loss: 0.0024\n",
      "Epoch 468/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3402e-06 - val_loss: 0.0027\n",
      "Epoch 469/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6742e-06 - val_loss: 0.0024\n",
      "Epoch 470/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.0602e-06 - val_loss: 0.0024\n",
      "Epoch 471/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.7434e-06 - val_loss: 0.0023\n",
      "Epoch 472/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.7822e-06 - val_loss: 0.0027\n",
      "Epoch 473/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.5854e-06 - val_loss: 0.0022\n",
      "Epoch 474/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 9.9164e-06 - val_loss: 0.0024\n",
      "Epoch 475/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5687e-06 - val_loss: 0.0028\n",
      "Epoch 476/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.1150e-06 - val_loss: 0.0026\n",
      "Epoch 477/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.7996e-06 - val_loss: 0.0022\n",
      "Epoch 478/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.7030e-06 - val_loss: 0.0026\n",
      "Epoch 479/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6933e-06 - val_loss: 0.0024\n",
      "Epoch 480/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.5858e-06 - val_loss: 0.0023\n",
      "Epoch 481/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4887e-06 - val_loss: 0.0025\n",
      "Epoch 482/500\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7.1014e-06 - val_loss: 0.0025\n",
      "Epoch 483/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.8140e-06 - val_loss: 0.0021\n",
      "Epoch 484/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.7867e-06 - val_loss: 0.0025\n",
      "Epoch 485/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.3241e-06 - val_loss: 0.0023\n",
      "Epoch 486/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.0905e-06 - val_loss: 0.0022\n",
      "Epoch 487/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2397e-06 - val_loss: 0.0023\n",
      "Epoch 488/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.2102e-06 - val_loss: 0.0025\n",
      "Epoch 489/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9289e-06 - val_loss: 0.0022\n",
      "Epoch 490/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.9979e-06 - val_loss: 0.0020\n",
      "Epoch 491/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.4256e-06 - val_loss: 0.0027\n",
      "Epoch 492/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 9.2253e-06 - val_loss: 0.0029\n",
      "Epoch 493/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8.4066e-06 - val_loss: 0.0021\n",
      "Epoch 494/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 8.6051e-06 - val_loss: 0.0025\n",
      "Epoch 495/500\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 7.1632e-06 - val_loss: 0.0026\n",
      "Epoch 496/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6189e-06 - val_loss: 0.0028\n",
      "Epoch 497/500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 7.2496e-06 - val_loss: 0.0028\n",
      "Epoch 498/500\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7.6572e-06 - val_loss: 0.0021\n",
      "Epoch 499/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8.1432e-06 - val_loss: 0.0027\n",
      "Epoch 500/500\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7.1392e-06 - val_loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e1a24f6e50>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, ytest), epochs=500, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJyw3fTCMBr4"
   },
   "source": [
    "**Step_3: Get results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformback to original form\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwAlq5MftPVL"
   },
   "source": [
    "**Step_4: Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.2850406551548"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y_train, train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.1097849598349"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(ytest, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scaler.inverse_transform(ytest.reshape(-1,1)), color = 'black', label = 'AAPL Stock Price')\n",
    "plt.plot(test_predict, color = 'green', label = 'Predicted AAPL Stock Price')\n",
    "plt.title('AAPL Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('AAPL Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_Practice1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Internship",
   "language": "python",
   "name": "internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
